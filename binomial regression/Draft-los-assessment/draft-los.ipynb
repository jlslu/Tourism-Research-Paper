{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the input Excel file...\n",
      "Loading data from: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/1.0 Data cleaning/Final data for model/stata raw data.xlsx\n",
      "\n",
      "Missing data summary:\n",
      "los                         75\n",
      "age                          0\n",
      "sex                         26\n",
      "marital_status              12\n",
      "employment_status          425\n",
      "distance_miles               0\n",
      "purpose                    403\n",
      "accomd_type                  0\n",
      "state_percapita_income       0\n",
      "state_unemployment           0\n",
      "travel_date                  0\n",
      "month_travel                 0\n",
      "import_from_slu              0\n",
      "immigrant_population         0\n",
      "us_state                     0\n",
      "sex_enc                      0\n",
      "marital_status_enc           0\n",
      "employment_status_enc        0\n",
      "purpose_enc                  0\n",
      "accomd_type_enc              0\n",
      "us_state_enc                 0\n",
      "los_trunc                 2178\n",
      "dtype: int64\n",
      "\n",
      "Missing data patterns:\n",
      "0    142227\n",
      "1      2910\n",
      "2       103\n",
      "3         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of stay by purpose:\n",
      "              count        mean  median  min      max          std\n",
      "purpose_enc                                                       \n",
      "-1              389    7.748072     6.0  2.0    373.0    19.536597\n",
      " 0             2131    6.845612     4.0  1.0    372.0    21.176125\n",
      " 1              425    6.334118     5.0  1.0    368.0    18.004622\n",
      " 2              175    7.000000     4.0  1.0    124.0    13.963005\n",
      " 3              432    4.282407     4.0  1.0     17.0     2.203955\n",
      " 4                2    7.000000     7.0  7.0      7.0     0.000000\n",
      " 5              407    6.154791     5.0  2.0     92.0     6.614890\n",
      " 6            22066    6.658253     6.0  1.0    372.0     6.694363\n",
      " 7             1212   69.916667     7.0  1.0  73109.0  2099.927812\n",
      " 8             1361  119.255694     7.0  1.0  73055.0  2799.175773\n",
      " 9           102372    8.927089     6.0  1.0  64986.0   264.902993\n",
      " 10              28    9.857143     7.0  2.0     29.0     6.948031\n",
      " 11            1399    7.987848     7.0  1.0    159.0     7.711945\n",
      " 12             377    6.785146     5.0  1.0    157.0    10.564593\n",
      " 13             177    5.762712     5.0  1.0     42.0     4.328837\n",
      " 14              42   12.214286     7.0  3.0    166.0    24.656208\n",
      " 15            3439   13.221867     8.0  1.0    393.0    25.614415\n",
      " 16            6623    6.179828     5.0  1.0    375.0    14.807467\n",
      " 17               6    6.333333     6.0  6.0      7.0     0.516398\n",
      "\n",
      "Detailed summary of length of stay:\n",
      "count    143063.000000\n",
      "mean         10.035565\n",
      "std         402.763642\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%           6.000000\n",
      "75%           7.000000\n",
      "90%           8.000000\n",
      "95%          10.000000\n",
      "99%          28.000000\n",
      "max       73109.000000\n",
      "Name: los_trunc, dtype: float64\n",
      "\n",
      "Number of missing values per observation:\n",
      "missing\n",
      "0    145166\n",
      "1        75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Remaining observations after dropping missing values: 145166\n",
      "After filtering to 95th percentile, remaining observations: 136252\n",
      "\n",
      "Purpose simple distribution:\n",
      "1.0 (Business): 898\n",
      "2.0 (Events): 22537\n",
      "3.0 (Wedding): 6\n",
      "4.0 (Pleasure): 1007\n",
      "5.0 (Other): 108945\n",
      "\n",
      "Fitting simple negative binomial regression model...\n",
      "Model formula: los_capped ~ immigrant_population + import_from_slu + age + distance_miles + state_percapita_income + state_unemployment + C(sex_enc) + C(marital_status_enc) + C(employment_status_enc) + C(purpose_simple) + C(accomd_type_enc) + C(month_travel) + C(us_state_enc)\n",
      "Number of rows in df_clean_nb after dropping missing values: 132166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative Binomial Regression Results:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             los_capped   No. Observations:               132166\n",
      "Model:                            GLM   Df Residuals:                   132090\n",
      "Model Family:        NegativeBinomial   Df Model:                           75\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -3.7528e+05\n",
      "Date:                Mon, 19 May 2025   Deviance:                       8275.2\n",
      "Time:                        13:37:01   Pearson chi2:                 7.89e+03\n",
      "No. Iterations:                    29   Pseudo R-squ. (CS):           0.007033\n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.4799      0.241      1.992      0.046       0.008       0.952\n",
      "C(sex_enc)[T.0]                  -0.1081      0.230     -0.471      0.638      -0.558       0.342\n",
      "C(sex_enc)[T.1]                  -0.0966      0.230     -0.421      0.674      -0.547       0.354\n",
      "C(marital_status_enc)[T.0]        0.0613      0.315      0.194      0.846      -0.556       0.679\n",
      "C(marital_status_enc)[T.1]        0.0358      0.316      0.113      0.910      -0.583       0.655\n",
      "C(marital_status_enc)[T.2]        0.0186      0.315      0.059      0.953      -0.599       0.636\n",
      "C(employment_status_enc)[T.0]    -0.0037      0.056     -0.066      0.948      -0.113       0.106\n",
      "C(employment_status_enc)[T.1]     0.0119      0.066      0.180      0.857      -0.117       0.141\n",
      "C(employment_status_enc)[T.2]    -0.0074      0.073     -0.101      0.919      -0.151       0.136\n",
      "C(purpose_simple)[T.2.0]          0.3525      0.038      9.221      0.000       0.278       0.427\n",
      "C(purpose_simple)[T.3.0]          0.3264      0.441      0.740      0.459      -0.538       1.191\n",
      "C(purpose_simple)[T.4.0]          0.2332      0.051      4.594      0.000       0.134       0.333\n",
      "C(purpose_simple)[T.5.0]          0.2162      0.037      5.781      0.000       0.143       0.289\n",
      "C(accomd_type_enc)[T.1]           0.0515      0.016      3.149      0.002       0.019       0.084\n",
      "C(accomd_type_enc)[T.2]           0.0956      0.009     10.281      0.000       0.077       0.114\n",
      "C(month_travel)[T.2]             -0.0111      0.015     -0.735      0.462      -0.041       0.018\n",
      "C(month_travel)[T.3]              0.0002      0.015      0.017      0.987      -0.029       0.029\n",
      "C(month_travel)[T.4]             -0.0192      0.015     -1.245      0.213      -0.049       0.011\n",
      "C(month_travel)[T.5]             -0.0194      0.015     -1.307      0.191      -0.049       0.010\n",
      "C(month_travel)[T.6]             -0.0115      0.015     -0.781      0.435      -0.040       0.017\n",
      "C(month_travel)[T.7]              0.0220      0.015      1.495      0.135      -0.007       0.051\n",
      "C(month_travel)[T.8]             -0.0400      0.016     -2.556      0.011      -0.071      -0.009\n",
      "C(month_travel)[T.9]             -0.0358      0.017     -2.066      0.039      -0.070      -0.002\n",
      "C(month_travel)[T.10]            -0.0332      0.016     -2.082      0.037      -0.064      -0.002\n",
      "C(month_travel)[T.11]            -0.0201      0.016     -1.287      0.198      -0.051       0.011\n",
      "C(month_travel)[T.12]             0.0317      0.015      2.080      0.037       0.002       0.062\n",
      "C(us_state_enc)[T.2]             -0.0916      0.227     -0.405      0.686      -0.536       0.352\n",
      "C(us_state_enc)[T.3]              0.0719      0.043      1.662      0.097      -0.013       0.157\n",
      "C(us_state_enc)[T.4]           7.711e-05      0.042      0.002      0.999      -0.082       0.083\n",
      "C(us_state_enc)[T.5]             -0.1582      0.053     -2.959      0.003      -0.263      -0.053\n",
      "C(us_state_enc)[T.6]             -0.1265      0.054     -2.328      0.020      -0.233      -0.020\n",
      "C(us_state_enc)[T.7]             -0.1702      0.058     -2.913      0.004      -0.285      -0.056\n",
      "C(us_state_enc)[T.8]             -0.0042      0.052     -0.081      0.935      -0.106       0.098\n",
      "C(us_state_enc)[T.9]              0.0247      0.011      2.177      0.030       0.002       0.047\n",
      "C(us_state_enc)[T.10]            -0.0206      0.022     -0.943      0.346      -0.063       0.022\n",
      "C(us_state_enc)[T.11]             0.0171      0.149      0.115      0.908      -0.275       0.309\n",
      "C(us_state_enc)[T.12]             0.0728      0.074      0.987      0.324      -0.072       0.217\n",
      "C(us_state_enc)[T.13]            -0.1434      0.058     -2.494      0.013      -0.256      -0.031\n",
      "C(us_state_enc)[T.14]            -0.0006      0.040     -0.015      0.988      -0.079       0.078\n",
      "C(us_state_enc)[T.15]             0.0030      0.042      0.071      0.943      -0.079       0.085\n",
      "C(us_state_enc)[T.16]            -0.0893      0.044     -2.011      0.044      -0.176      -0.002\n",
      "C(us_state_enc)[T.17]             0.0185      0.044      0.417      0.677      -0.068       0.105\n",
      "C(us_state_enc)[T.18]            -0.0993      0.042     -2.338      0.019      -0.182      -0.016\n",
      "C(us_state_enc)[T.20]             0.1098      0.046      2.364      0.018       0.019       0.201\n",
      "C(us_state_enc)[T.21]            -0.0743      0.034     -2.199      0.028      -0.141      -0.008\n",
      "C(us_state_enc)[T.22]            -0.1790      0.069     -2.577      0.010      -0.315      -0.043\n",
      "C(us_state_enc)[T.23]            -0.0023      0.041     -0.056      0.955      -0.082       0.078\n",
      "C(us_state_enc)[T.24]             0.0109      0.040      0.274      0.784      -0.067       0.089\n",
      "C(us_state_enc)[T.25]             0.0483      0.039      1.240      0.215      -0.028       0.125\n",
      "C(us_state_enc)[T.26]            -0.0470      0.034     -1.395      0.163      -0.113       0.019\n",
      "C(us_state_enc)[T.27]             0.0386      0.078      0.497      0.619      -0.114       0.191\n",
      "C(us_state_enc)[T.28]            -0.0869      0.046     -1.874      0.061      -0.178       0.004\n",
      "C(us_state_enc)[T.29]            -0.1232      0.066     -1.877      0.061      -0.252       0.005\n",
      "C(us_state_enc)[T.30]             0.0390      0.043      0.905      0.366      -0.046       0.124\n",
      "C(us_state_enc)[T.31]            -0.1254      0.051     -2.479      0.013      -0.224      -0.026\n",
      "C(us_state_enc)[T.32]             0.0436      0.084      0.522      0.602      -0.120       0.207\n",
      "C(us_state_enc)[T.33]             0.0494      0.015      3.267      0.001       0.020       0.079\n",
      "C(us_state_enc)[T.34]            -0.0288      0.032     -0.903      0.366      -0.091       0.034\n",
      "C(us_state_enc)[T.35]            -0.0165      0.088     -0.189      0.850      -0.188       0.155\n",
      "C(us_state_enc)[T.36]            -0.0043      0.038     -0.111      0.911      -0.080       0.071\n",
      "C(us_state_enc)[T.37]            -0.0460      0.039     -1.167      0.243      -0.123       0.031\n",
      "C(us_state_enc)[T.38]             0.0771      0.067      1.143      0.253      -0.055       0.209\n",
      "C(us_state_enc)[T.39]             0.0082      0.033      0.246      0.806      -0.057       0.073\n",
      "C(us_state_enc)[T.40]            -0.0017      0.059     -0.028      0.977      -0.117       0.114\n",
      "C(us_state_enc)[T.41]            -0.0445      0.040     -1.099      0.272      -0.124       0.035\n",
      "C(us_state_enc)[T.42]            -0.0338      0.067     -0.504      0.614      -0.165       0.098\n",
      "C(us_state_enc)[T.43]            -0.0272      0.031     -0.870      0.384      -0.088       0.034\n",
      "C(us_state_enc)[T.44]            -0.0683      0.025     -2.757      0.006      -0.117      -0.020\n",
      "C(us_state_enc)[T.46]             0.0362      0.057      0.636      0.525      -0.075       0.148\n",
      "C(us_state_enc)[T.47]             0.1142      0.066      1.730      0.084      -0.015       0.244\n",
      "C(us_state_enc)[T.48]            -0.0473      0.036     -1.323      0.186      -0.117       0.023\n",
      "C(us_state_enc)[T.49]            -0.0765      0.060     -1.277      0.202      -0.194       0.041\n",
      "C(us_state_enc)[T.51]             0.1331      0.065      2.056      0.040       0.006       0.260\n",
      "C(us_state_enc)[T.52]             0.0758      0.032      2.402      0.016       0.014       0.138\n",
      "C(us_state_enc)[T.53]            -0.2280      0.095     -2.388      0.017      -0.415      -0.041\n",
      "immigrant_population          -2.137e-05      6e-06     -3.559      0.000   -3.31e-05    -9.6e-06\n",
      "import_from_slu               -4.176e-09   7.05e-09     -0.592      0.554    -1.8e-08    9.65e-09\n",
      "age                               0.0026      0.000     10.760      0.000       0.002       0.003\n",
      "distance_miles                 2.117e-05    2.8e-05      0.757      0.449   -3.37e-05     7.6e-05\n",
      "state_percapita_income         1.406e-05   3.01e-06      4.676      0.000    8.17e-06       2e-05\n",
      "state_unemployment                0.0473      0.018      2.651      0.008       0.012       0.082\n",
      "=================================================================================================\n",
      "\n",
      "Incident Rate Ratios (IRR):\n",
      "                                 IRR  Lower CI  Upper CI       P-value\n",
      "Intercept                   1.615968  1.007816  2.591102  4.634010e-02\n",
      "C(sex_enc)[T.0]             0.897549  0.572279  1.407695  6.378350e-01\n",
      "C(sex_enc)[T.1]             0.907933  0.578873  1.424048  6.740542e-01\n",
      "C(marital_status_enc)[T.0]  1.063201  0.573297  1.971746  8.458033e-01\n",
      "C(marital_status_enc)[T.1]  1.036492  0.558166  1.924723  9.096359e-01\n",
      "...                              ...       ...       ...           ...\n",
      "import_from_slu             1.000000  1.000000  1.000000  5.537492e-01\n",
      "age                         1.002597  1.002123  1.003071  5.343849e-27\n",
      "distance_miles              1.000021  0.999966  1.000076  4.492405e-01\n",
      "state_percapita_income      1.000014  1.000008  1.000020  2.922790e-06\n",
      "state_unemployment          1.048418  1.012406  1.085711  8.017647e-03\n",
      "\n",
      "[81 rows x 4 columns]\n",
      "Columns in df_clean_nb: ['los_capped', 'immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_percapita_income', 'state_unemployment', 'sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc', 'predicted', 'residuals']\n",
      "Checking if 'us_state_enc' is in df_clean_nb.columns: True\n",
      "X dtypes after converting to float:\n",
      "const                      float64\n",
      "immigrant_population       float64\n",
      "import_from_slu            float64\n",
      "age                        float64\n",
      "distance_miles             float64\n",
      "state_unemployment         float64\n",
      "sex_enc_1                  float64\n",
      "marital_status_enc_1       float64\n",
      "marital_status_enc_2       float64\n",
      "employment_status_enc_0    float64\n",
      "employment_status_enc_1    float64\n",
      "employment_status_enc_2    float64\n",
      "purpose_simple_2.0         float64\n",
      "purpose_simple_3.0         float64\n",
      "purpose_simple_4.0         float64\n",
      "purpose_simple_5.0         float64\n",
      "accomd_type_enc_1          float64\n",
      "accomd_type_enc_2          float64\n",
      "month_travel_2             float64\n",
      "month_travel_3             float64\n",
      "month_travel_4             float64\n",
      "month_travel_5             float64\n",
      "month_travel_6             float64\n",
      "month_travel_7             float64\n",
      "month_travel_8             float64\n",
      "month_travel_9             float64\n",
      "month_travel_10            float64\n",
      "month_travel_11            float64\n",
      "month_travel_12            float64\n",
      "dtype: object\n",
      "Length of df_clean_model: 132122\n",
      "Length of y: 132122\n",
      "Number of rows in X: 132122\n",
      "Length of groups: 132122\n",
      "\n",
      "Approximated Multilevel Model Results:\n",
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:               MixedLM    Dependent Variable:    los_capped  \n",
      "No. Observations:    132122     Method:                REML        \n",
      "No. Groups:          50         Scale:                 2.3255      \n",
      "Min. group size:     18         Log-Likelihood:        -243415.6145\n",
      "Max. group size:     15803      Converged:             Yes         \n",
      "Mean group size:     2642.4                                        \n",
      "-------------------------------------------------------------------\n",
      "                        Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "const                    3.918    0.258  15.201 0.000  3.413  4.424\n",
      "immigrant_population    -0.000    0.000  -1.087 0.277 -0.000  0.000\n",
      "import_from_slu         -0.000    0.000  -1.447 0.148 -0.000  0.000\n",
      "age                      0.015    0.000  44.699 0.000  0.015  0.016\n",
      "distance_miles           0.000    0.000   3.757 0.000  0.000  0.000\n",
      "state_unemployment      -0.078    0.053  -1.475 0.140 -0.182  0.026\n",
      "sex_enc_1                0.062    0.009   7.314 0.000  0.046  0.079\n",
      "marital_status_enc_1    -0.151    0.030  -5.035 0.000 -0.209 -0.092\n",
      "marital_status_enc_2    -0.238    0.010 -22.845 0.000 -0.258 -0.217\n",
      "employment_status_enc_0 -0.016    0.079  -0.198 0.843 -0.171  0.139\n",
      "employment_status_enc_1  0.069    0.093   0.738 0.461 -0.114  0.251\n",
      "employment_status_enc_2 -0.033    0.103  -0.318 0.750 -0.235  0.169\n",
      "purpose_simple_2.0       1.929    0.053  36.428 0.000  1.825  2.032\n",
      "purpose_simple_3.0       1.748    0.625   2.797 0.005  0.523  2.972\n",
      "purpose_simple_4.0       1.234    0.071  17.399 0.000  1.095  1.373\n",
      "purpose_simple_5.0       1.136    0.052  21.953 0.000  1.034  1.237\n",
      "accomd_type_enc_1        0.294    0.023  12.738 0.000  0.249  0.339\n",
      "accomd_type_enc_2        0.552    0.013  42.028 0.000  0.526  0.578\n",
      "month_travel_2          -0.066    0.021  -3.112 0.002 -0.108 -0.025\n",
      "month_travel_3          -0.010    0.021  -0.489 0.625 -0.051  0.031\n",
      "month_travel_4          -0.123    0.022  -5.635 0.000 -0.165 -0.080\n",
      "month_travel_5          -0.126    0.021  -5.991 0.000 -0.167 -0.084\n",
      "month_travel_6          -0.077    0.021  -3.709 0.000 -0.118 -0.036\n",
      "month_travel_7           0.108    0.021   5.206 0.000  0.068  0.149\n",
      "month_travel_8          -0.238    0.022 -10.822 0.000 -0.281 -0.195\n",
      "month_travel_9          -0.212    0.024  -8.706 0.000 -0.260 -0.164\n",
      "month_travel_10         -0.193    0.022  -8.615 0.000 -0.237 -0.149\n",
      "month_travel_11         -0.122    0.022  -5.560 0.000 -0.165 -0.079\n",
      "month_travel_12          0.169    0.022   7.861 0.000  0.127  0.212\n",
      "Group Var                0.085    0.013                            \n",
      "===================================================================\n",
      "\n",
      "\n",
      "Incident Rate Ratios (IRR) Mixed Model:\n",
      "                               IRR   Lower CI   Upper CI        P-value\n",
      "const                    50.318982  30.360771  83.397089   3.496185e-52\n",
      "immigrant_population      0.999970   0.999917   1.000024   2.771542e-01\n",
      "import_from_slu           1.000000   1.000000   1.000000   1.480236e-01\n",
      "age                       1.015342   1.014665   1.016020   0.000000e+00\n",
      "distance_miles            1.000211   1.000101   1.000321   1.719048e-04\n",
      "state_unemployment        0.925027   0.834014   1.025972   1.402762e-01\n",
      "sex_enc_1                 1.064294   1.046671   1.082214   2.588811e-13\n",
      "marital_status_enc_1      0.860069   0.811051   0.912048   4.781685e-07\n",
      "marital_status_enc_2      0.788369   0.772449   0.804618  1.641904e-115\n",
      "employment_status_enc_0   0.984480   0.843044   1.149645   8.433054e-01\n",
      "employment_status_enc_1   1.071151   0.892352   1.285776   4.607279e-01\n",
      "employment_status_enc_2   0.967717   0.790559   1.184574   7.504163e-01\n",
      "purpose_simple_2.0        6.880059   6.201932   7.632334  1.515587e-290\n",
      "purpose_simple_3.0        5.740482   1.686709  19.536946   5.165040e-03\n",
      "purpose_simple_4.0        3.434888   2.989108   3.947150   8.458193e-68\n",
      "purpose_simple_5.0        3.113014   2.812872   3.445183  8.103887e-107\n",
      "accomd_type_enc_1         1.341665   1.282340   1.403735   3.655720e-37\n",
      "accomd_type_enc_2         1.736728   1.692591   1.782016   0.000000e+00\n",
      "month_travel_2            0.935913   0.897671   0.975785   1.860807e-03\n",
      "month_travel_3            0.989848   0.950144   1.031212   6.251828e-01\n",
      "month_travel_4            0.884677   0.847765   0.923197   1.750987e-08\n",
      "month_travel_5            0.882043   0.846560   0.919013   2.080791e-09\n",
      "month_travel_6            0.925884   0.888964   0.964338   2.080729e-04\n",
      "month_travel_7            1.114398   1.069867   1.160784   1.932536e-07\n",
      "month_travel_8            0.788005   0.754725   0.822753   2.722788e-27\n",
      "month_travel_9            0.808796   0.771067   0.848371   3.134883e-18\n",
      "month_travel_10           0.824239   0.788778   0.861295   6.995888e-18\n",
      "month_travel_11           0.884887   0.847552   0.923867   2.692657e-08\n",
      "month_travel_12           1.184525   1.135555   1.235606   3.802696e-15\n",
      "Group Var                 1.037133   1.020406   1.054133   1.107069e-05\n",
      "VIF for continuous and dummy variables:\n",
      "                   Variable         VIF\n",
      "0      immigrant_population    1.727610\n",
      "1           import_from_slu    1.467135\n",
      "2                       age   14.004422\n",
      "3            distance_miles   25.566667\n",
      "4        state_unemployment   42.585432\n",
      "5                 sex_enc_1    1.846151\n",
      "6      marital_status_enc_1    1.039072\n",
      "7      marital_status_enc_2    1.671903\n",
      "8   employment_status_enc_0  139.146812\n",
      "9   employment_status_enc_1    2.006506\n",
      "10  employment_status_enc_2    1.563465\n",
      "11       purpose_simple_2.0   19.601597\n",
      "12       purpose_simple_3.0    1.005534\n",
      "13       purpose_simple_4.0    1.825910\n",
      "14       purpose_simple_5.0   90.791837\n",
      "15        accomd_type_enc_1    1.044681\n",
      "16        accomd_type_enc_2    1.196158\n",
      "17           month_travel_2    2.222184\n",
      "18           month_travel_3    2.339551\n",
      "19           month_travel_4    2.114337\n",
      "20           month_travel_5    2.354183\n",
      "21           month_travel_6    2.445633\n",
      "22           month_travel_7    2.426972\n",
      "23           month_travel_8    2.088112\n",
      "24           month_travel_9    1.737700\n",
      "25          month_travel_10    2.006430\n",
      "26          month_travel_11    2.074571\n",
      "27          month_travel_12    2.171225\n",
      "\n",
      "Approximated Multilevel Model Results:\n",
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:               MixedLM    Dependent Variable:    los_capped  \n",
      "No. Observations:    132122     Method:                REML        \n",
      "No. Groups:          50         Scale:                 2.3254      \n",
      "Min. group size:     18         Log-Likelihood:        -243411.3186\n",
      "Max. group size:     15803      Converged:             Yes         \n",
      "Mean group size:     2642.4                                        \n",
      "-------------------------------------------------------------------\n",
      "                        Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "const                    4.198    0.110  38.151 0.000  3.982  4.413\n",
      "immigrant_population    -0.000    0.000  -1.583 0.114 -0.000  0.000\n",
      "import_from_slu         -0.000    0.000  -1.499 0.134 -0.000  0.000\n",
      "age                      0.015    0.000  44.703 0.000  0.015  0.016\n",
      "sex_enc_1                0.062    0.009   7.311 0.000  0.046  0.079\n",
      "marital_status_enc_1    -0.151    0.030  -5.039 0.000 -0.210 -0.092\n",
      "marital_status_enc_2    -0.238    0.010 -22.843 0.000 -0.258 -0.217\n",
      "employment_status_enc_0 -0.016    0.079  -0.196 0.844 -0.171  0.140\n",
      "employment_status_enc_1  0.069    0.093   0.737 0.461 -0.114  0.251\n",
      "employment_status_enc_2 -0.033    0.103  -0.319 0.749 -0.235  0.169\n",
      "purpose_simple_2.0       1.929    0.053  36.430 0.000  1.825  2.032\n",
      "purpose_simple_3.0       1.748    0.625   2.797 0.005  0.523  2.973\n",
      "purpose_simple_4.0       1.235    0.071  17.412 0.000  1.096  1.374\n",
      "purpose_simple_5.0       1.136    0.052  21.954 0.000  1.034  1.237\n",
      "accomd_type_enc_1        0.294    0.023  12.750 0.000  0.249  0.339\n",
      "accomd_type_enc_2        0.552    0.013  42.041 0.000  0.526  0.578\n",
      "month_travel_2          -0.067    0.021  -3.130 0.002 -0.108 -0.025\n",
      "month_travel_3          -0.011    0.021  -0.508 0.611 -0.052  0.030\n",
      "month_travel_4          -0.123    0.022  -5.657 0.000 -0.166 -0.080\n",
      "month_travel_5          -0.126    0.021  -6.009 0.000 -0.167 -0.085\n",
      "month_travel_6          -0.077    0.021  -3.720 0.000 -0.118 -0.037\n",
      "month_travel_7           0.108    0.021   5.194 0.000  0.067  0.149\n",
      "month_travel_8          -0.239    0.022 -10.837 0.000 -0.282 -0.195\n",
      "month_travel_9          -0.213    0.024  -8.719 0.000 -0.260 -0.165\n",
      "month_travel_10         -0.194    0.022  -8.630 0.000 -0.238 -0.150\n",
      "month_travel_11         -0.123    0.022  -5.573 0.000 -0.166 -0.079\n",
      "month_travel_12          0.169    0.022   7.844 0.000  0.127  0.211\n",
      "Group Var                0.114    0.016                            \n",
      "===================================================================\n",
      "\n",
      "\n",
      "Incident Rate Ratios (IRR) Mixed Model:\n",
      "                               IRR   Lower CI   Upper CI        P-value\n",
      "const                    66.532601  53.626193  82.545239   0.000000e+00\n",
      "immigrant_population      0.999951   0.999890   1.000012   1.135311e-01\n",
      "import_from_slu           1.000000   1.000000   1.000000   1.338381e-01\n",
      "age                       1.015344   1.014666   1.016022   0.000000e+00\n",
      "sex_enc_1                 1.064266   1.046643   1.082186   2.648162e-13\n",
      "marital_status_enc_1      0.859970   0.810959   0.911944   4.686723e-07\n",
      "marital_status_enc_2      0.788384   0.772463   0.804633  1.710903e-115\n",
      "employment_status_enc_0   0.984576   0.843127   1.149756   8.442706e-01\n",
      "employment_status_enc_1   1.071096   0.892307   1.285709   4.610592e-01\n",
      "employment_status_enc_2   0.967580   0.790448   1.184405   7.493724e-01\n",
      "purpose_simple_2.0        6.880630   6.202448   7.632966  1.426409e-290\n",
      "purpose_simple_3.0        5.741803   1.687110  19.541283   5.158870e-03\n",
      "purpose_simple_4.0        3.438078   2.991887   3.950812   6.715306e-68\n",
      "purpose_simple_5.0        3.113221   2.813060   3.445411  7.863053e-107\n",
      "accomd_type_enc_1         1.342039   1.282698   1.404126   3.128380e-37\n",
      "accomd_type_enc_2         1.737022   1.692878   1.782318   0.000000e+00\n",
      "month_travel_2            0.935541   0.897314   0.975396   1.746146e-03\n",
      "month_travel_3            0.989445   0.949757   1.030791   6.114289e-01\n",
      "month_travel_4            0.884248   0.847354   0.922749   1.537674e-08\n",
      "month_travel_5            0.881709   0.846240   0.918665   1.861533e-09\n",
      "month_travel_6            0.925679   0.888767   0.964124   1.994375e-04\n",
      "month_travel_7            1.114129   1.069609   1.160503   2.056015e-07\n",
      "month_travel_8            0.787735   0.754466   0.822471   2.295580e-27\n",
      "month_travel_9            0.808552   0.770834   0.848115   2.808998e-18\n",
      "month_travel_10           0.823964   0.788515   0.861007   6.141558e-18\n",
      "month_travel_11           0.884637   0.847313   0.923606   2.500694e-08\n",
      "month_travel_12           1.184071   1.135121   1.235133   4.379870e-15\n",
      "Group Var                 1.050120   1.028856   1.071824   2.792463e-06\n",
      "VIF for continuous and dummy variables with fewer variables:\n",
      "                   Variable         VIF\n",
      "0      immigrant_population    1.547717\n",
      "1           import_from_slu    1.363094\n",
      "2                       age   13.942006\n",
      "3                 sex_enc_1    1.846004\n",
      "4      marital_status_enc_1    1.039063\n",
      "5      marital_status_enc_2    1.668119\n",
      "6   employment_status_enc_0  121.189563\n",
      "7   employment_status_enc_1    1.873709\n",
      "8   employment_status_enc_2    1.491955\n",
      "9        purpose_simple_2.0   19.071579\n",
      "10       purpose_simple_3.0    1.005454\n",
      "11       purpose_simple_4.0    1.805814\n",
      "12       purpose_simple_5.0   88.560006\n",
      "13        accomd_type_enc_1    1.044367\n",
      "14        accomd_type_enc_2    1.195577\n",
      "15           month_travel_2    2.219994\n",
      "16           month_travel_3    2.333580\n",
      "17           month_travel_4    2.111086\n",
      "18           month_travel_5    2.348608\n",
      "19           month_travel_6    2.434372\n",
      "20           month_travel_7    2.417859\n",
      "21           month_travel_8    2.082938\n",
      "22           month_travel_9    1.735213\n",
      "23          month_travel_10    2.002901\n",
      "24          month_travel_11    2.068635\n",
      "25          month_travel_12    2.165431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approximated Multilevel Model Results With Log Transformations:\n",
      "               Mixed Linear Model Regression Results\n",
      "====================================================================\n",
      "Model:                MixedLM   Dependent Variable:   log_los_capped\n",
      "No. Observations:     132122    Method:               REML          \n",
      "No. Groups:           50        Scale:                0.0785        \n",
      "Min. group size:      18        Log-Likelihood:       -19570.8670   \n",
      "Max. group size:      15803     Converged:            Yes           \n",
      "Mean group size:      2642.4                                        \n",
      "--------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------------------\n",
      "const                     1.257    0.084  14.948 0.000  1.092  1.421\n",
      "sex_enc_1                 0.011    0.002   7.157 0.000  0.008  0.014\n",
      "marital_status_enc_1     -0.026    0.005  -4.781 0.000 -0.037 -0.016\n",
      "marital_status_enc_2     -0.049    0.002 -25.480 0.000 -0.053 -0.045\n",
      "employment_status_enc_0  -0.009    0.015  -0.619 0.536 -0.037  0.019\n",
      "employment_status_enc_1   0.012    0.017   0.694 0.488 -0.022  0.045\n",
      "employment_status_enc_2  -0.011    0.019  -0.569 0.569 -0.048  0.026\n",
      "purpose_simple_2.0        0.386    0.010  39.661 0.000  0.367  0.405\n",
      "purpose_simple_3.0        0.401    0.115   3.490 0.000  0.176  0.626\n",
      "purpose_simple_4.0        0.254    0.013  19.524 0.000  0.229  0.280\n",
      "purpose_simple_5.0        0.243    0.010  25.541 0.000  0.224  0.261\n",
      "accomd_type_enc_1         0.040    0.004   9.413 0.000  0.032  0.048\n",
      "accomd_type_enc_2         0.084    0.002  34.745 0.000  0.079  0.089\n",
      "month_travel_2           -0.011    0.004  -2.766 0.006 -0.018 -0.003\n",
      "month_travel_3            0.003    0.004   0.685 0.493 -0.005  0.010\n",
      "month_travel_4           -0.020    0.004  -5.084 0.000 -0.028 -0.012\n",
      "month_travel_5           -0.022    0.004  -5.775 0.000 -0.030 -0.015\n",
      "month_travel_6           -0.012    0.004  -3.230 0.001 -0.020 -0.005\n",
      "month_travel_7            0.022    0.004   5.823 0.000  0.015  0.030\n",
      "month_travel_8           -0.043    0.004 -10.531 0.000 -0.051 -0.035\n",
      "month_travel_9           -0.039    0.004  -8.707 0.000 -0.048 -0.030\n",
      "month_travel_10          -0.036    0.004  -8.712 0.000 -0.044 -0.028\n",
      "month_travel_11          -0.022    0.004  -5.567 0.000 -0.030 -0.015\n",
      "month_travel_12           0.031    0.004   7.735 0.000  0.023  0.038\n",
      "log_age                   0.003    0.000  38.854 0.000  0.002  0.003\n",
      "log_distance              0.000    0.000   2.144 0.032  0.000  0.001\n",
      "log_immigrant_population -0.001    0.001  -2.729 0.006 -0.002 -0.000\n",
      "log_import_from_slu      -0.000    0.000  -0.220 0.826 -0.000  0.000\n",
      "log_state_unemployment   -0.010    0.014  -0.715 0.475 -0.037  0.017\n",
      "Group Var                 0.002    0.002                            \n",
      "====================================================================\n",
      "\n",
      "\n",
      "Incident Rate Ratios (IRR) Mixed Model With Log Transformations:\n",
      "                               IRR  Lower CI  Upper CI        P-value\n",
      "const                     3.513675  2.979894  4.143070   1.610685e-50\n",
      "sex_enc_1                 1.011263  1.008166  1.014370   8.242325e-13\n",
      "marital_status_enc_1      0.974052  0.963610  0.984607   1.743469e-06\n",
      "marital_status_enc_2      0.952085  0.948496  0.955688  3.257100e-143\n",
      "employment_status_enc_0   0.991045  0.963207  1.019688   5.360459e-01\n",
      "employment_status_enc_1   1.011947  0.978560  1.046474   4.877856e-01\n",
      "employment_status_enc_2   0.989276  0.953204  1.026714   5.694273e-01\n",
      "purpose_simple_2.0        1.471024  1.443233  1.499350   0.000000e+00\n",
      "purpose_simple_3.0        1.492752  1.191999  1.869389   4.831172e-04\n",
      "purpose_simple_4.0        1.289659  1.257143  1.323015   6.819032e-85\n",
      "purpose_simple_5.0        1.274700  1.251179  1.298664  6.866119e-144\n",
      "accomd_type_enc_1         1.040707  1.032097  1.049389   4.803634e-21\n",
      "accomd_type_enc_2         1.087446  1.082316  1.092601  1.654900e-264\n",
      "month_travel_2            0.989244  0.981692  0.996855   5.683169e-03\n",
      "month_travel_3            1.002632  0.995120  1.010200   4.933677e-01\n",
      "month_travel_4            0.979897  0.972255  0.987598   3.692213e-07\n",
      "month_travel_5            0.978021  0.970672  0.985425   7.683959e-09\n",
      "month_travel_6            0.987757  0.980402  0.995168   1.238120e-03\n",
      "month_travel_7            1.022501  1.014871  1.030188   5.794726e-09\n",
      "month_travel_8            0.958309  0.950744  0.965935   6.236280e-26\n",
      "month_travel_9            0.961768  0.953365  0.970245   3.121042e-18\n",
      "month_travel_10           0.964730  0.956969  0.972555   2.978105e-18\n",
      "month_travel_11           0.977760  0.970048  0.985533   2.590800e-08\n",
      "month_travel_12           1.031081  1.023115  1.039109   1.037627e-14\n",
      "log_age                   1.002569  1.002440  1.002699   0.000000e+00\n",
      "log_distance              1.000349  1.000030  1.000667   3.200414e-02\n",
      "log_immigrant_population  0.998589  0.997577  0.999602   6.347687e-03\n",
      "log_import_from_slu       0.999966  0.999661  1.000271   8.256552e-01\n",
      "log_state_unemployment    0.990079  0.963385  1.017513   4.746116e-01\n",
      "Group Var                 1.029926  1.016208  1.043830   1.633363e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF for continuous and dummy variables With Log Transformations:\n",
      "                    Variable         VIF\n",
      "0                  sex_enc_1    1.846238\n",
      "1       marital_status_enc_1    1.038726\n",
      "2       marital_status_enc_2    1.700338\n",
      "3    employment_status_enc_0  189.431568\n",
      "4    employment_status_enc_1    2.367711\n",
      "5    employment_status_enc_2    1.768085\n",
      "6         purpose_simple_2.0   21.042367\n",
      "7         purpose_simple_3.0    1.005825\n",
      "8         purpose_simple_4.0    1.889196\n",
      "9         purpose_simple_5.0   97.723518\n",
      "10         accomd_type_enc_1    1.044606\n",
      "11         accomd_type_enc_2    1.196936\n",
      "12            month_travel_2    2.228739\n",
      "13            month_travel_3    2.343711\n",
      "14            month_travel_4    2.117767\n",
      "15            month_travel_5    2.357249\n",
      "16            month_travel_6    2.450757\n",
      "17            month_travel_7    2.434544\n",
      "18            month_travel_8    2.092371\n",
      "19            month_travel_9    1.741468\n",
      "20           month_travel_10    2.010486\n",
      "21           month_travel_11    2.077843\n",
      "22           month_travel_12    2.175078\n",
      "23                   log_age   22.471413\n",
      "24              log_distance  175.070772\n",
      "25  log_immigrant_population    8.617836\n",
      "26       log_import_from_slu    8.317395\n",
      "27    log_state_unemployment   42.446464\n",
      "\n",
      "Please select where to save the Word document...\n",
      "Analysis report saved to: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/log cub min 2 nights.docx\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families.family import NegativeBinomial\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from scipy import stats\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from io import BytesIO\n",
    "import statsmodels.discrete.discrete_model as discrete\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "def select_file(title, file_types, save=False):\n",
    "    \"\"\"Allow user to select a file\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    try:\n",
    "        if save:\n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types,\n",
    "                defaultextension=file_types[0][1]\n",
    "            )\n",
    "        else:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types\n",
    "            )\n",
    "    finally:\n",
    "        root.destroy()\n",
    "    \n",
    "    return file_path if file_path else None\n",
    "\n",
    "# Allow user to select input file\n",
    "print(\"Please select the input Excel file...\")\n",
    "file_path = select_file(\n",
    "    \"Select Excel Data File\", \n",
    "    [(\"Excel files\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "if not file_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Import the data\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"Sheet\")\n",
    "\n",
    "# Setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Encode categorical variables if not already encoded\n",
    "categorical_vars = ['sex', 'marital_status', 'employment_status', 'purpose', 'accomd_type', 'us_state']\n",
    "encoded_vars = {}\n",
    "\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        # Check if variable is already numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df[var]):\n",
    "            new_var = f\"{var}_enc\"\n",
    "            df[new_var] = pd.Categorical(df[var]).codes\n",
    "            encoded_vars[var] = new_var\n",
    "        else:\n",
    "            encoded_vars[var] = var\n",
    "\n",
    "# Set the truncation point for los (assuming truncation at 0)\n",
    "df['los_trunc'] = df['los'].copy()\n",
    "df.loc[df['los_trunc'] <= 0, 'los_trunc'] = np.nan\n",
    "\n",
    "# Check for missing data\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing_data_summary = df.isnull().sum()\n",
    "print(missing_data_summary)\n",
    "\n",
    "print(\"\\nMissing data patterns:\")\n",
    "missing_patterns = df.isnull().sum(axis=1)\n",
    "missing_patterns_counts = missing_patterns.value_counts().sort_index()\n",
    "print(missing_patterns_counts)\n",
    "\n",
    "# Visualize los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['los_trunc'], discrete=True)\n",
    "plt.title('Histogram of Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_hist_img = BytesIO()\n",
    "plt.savefig(los_hist_img, format='png')\n",
    "los_hist_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Summarize los by purpose\n",
    "purpose_stats = None\n",
    "if 'purpose_enc' in df.columns:\n",
    "    print(\"\\nLength of stay by purpose:\")\n",
    "    purpose_stats = df.groupby('purpose_enc')['los_trunc'].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    print(purpose_stats)\n",
    "\n",
    "# Detailed summary of los_trunc\n",
    "print(\"\\nDetailed summary of length of stay:\")\n",
    "los_describe = df['los_trunc'].describe(percentiles=[.25, .5, .75, .90, .95, .99])\n",
    "print(los_describe)\n",
    "\n",
    "# Cleaning process\n",
    "# Step 1: Drop missing datapoints for key variables\n",
    "key_vars = ['los', 'immigrant_population', 'import_from_slu', 'age', \n",
    "            encoded_vars.get('sex', 'sex_enc'), \n",
    "            encoded_vars.get('marital_status', 'marital_status_enc'), \n",
    "            encoded_vars.get('employment_status', 'employment_status_enc'), \n",
    "            'distance_miles', \n",
    "            encoded_vars.get('purpose', 'purpose_enc'), \n",
    "            encoded_vars.get('accomd_type', 'accomd_type_enc'), \n",
    "            'month_travel', 'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Count missing values per row for key variables\n",
    "df['missing'] = df[key_vars].isnull().sum(axis=1)\n",
    "print(\"\\nNumber of missing values per observation:\")\n",
    "missing_values_count = df['missing'].value_counts().sort_index()\n",
    "print(missing_values_count)\n",
    "\n",
    "# Drop observations with missing values in key variables\n",
    "df_clean = df[df['missing'] == 0].drop('missing', axis=1)\n",
    "print(f\"\\nRemaining observations after dropping missing values: {len(df_clean)}\")\n",
    "\n",
    "# Step 2: Drop outliers in length of stay\n",
    "los_p95 = np.percentile(df_clean['los_trunc'].dropna(), 95)\n",
    "df_clean['los_capped'] = df_clean['los_trunc'].copy()\n",
    "df_clean.loc[df_clean['los_capped'] > los_p95, 'los_capped'] = los_p95\n",
    "\n",
    "df_clean = df_clean[df_clean['los_trunc'] <= los_p95]\n",
    "print(f\"After filtering to 95th percentile, remaining observations: {len(df_clean)}\")\n",
    "\n",
    "# Remove any instance of los_capped that is less than 2. Prior to this, over 1000 persons had stays less than 1 including honeymooners. This appears to be a data entry error.\n",
    "df_clean = df_clean[df_clean['los_capped'] >= 2]\n",
    "\n",
    "# Visualize the capped los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['los_capped'], discrete=True)\n",
    "plt.title('Histogram of Capped Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_capped_img = BytesIO()\n",
    "plt.savefig(los_capped_img, format='png')\n",
    "los_capped_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Clean up the purpose of trip column\n",
    "# Create a new simplified purpose variable\n",
    "purpose_mapping = {\n",
    "    1: 1,  # BUSINESS/MEETING -> Business\n",
    "    2: 1,  # CONVENTION -> Business\n",
    "    3: 1,  # CREW -> Business\n",
    "    5: 2,  # EVENT -> Events\n",
    "    6: 2,  # EVENTS -> Events\n",
    "    7: 4,  # HONEYMOON -> Pleasure\n",
    "    8: 5,  # INTRANSIT PASSEN -> Other\n",
    "    9: 5,  # OTHER -> Other\n",
    "    10: 4, # PLEASURE/HOLIDAY -> Pleasure\n",
    "    11: 5, # RESIDENT -> Other\n",
    "    12: 2, # SAINT LUCIA CARN -> Events\n",
    "    13: 2, # SAINT LUCIA JAZZ -> Events\n",
    "    14: 5, # SPORTS -> Other\n",
    "    15: 5, # STUDY -> Other\n",
    "    16: 5, # VISITING FRIENDS -> Other\n",
    "    17: 3, # WEDDING -> Wedding\n",
    "    18: 4, # pLEASURE/HOLIDAY -> Pleasure\n",
    "    4: 5,  # CRICKET -> Other\n",
    "}\n",
    "\n",
    "purpose_labels = {\n",
    "    1: \"Business\",\n",
    "    2: \"Events\",\n",
    "    3: \"Wedding\",\n",
    "    4: \"Pleasure\",\n",
    "    5: \"Other\"\n",
    "}\n",
    "\n",
    "# Add the simplified purpose variable\n",
    "purpose_enc_col = encoded_vars.get('purpose', 'purpose_enc')\n",
    "df_clean['purpose_simple'] = df_clean[purpose_enc_col].map(purpose_mapping)\n",
    "\n",
    "# Check the new variable\n",
    "print(\"\\nPurpose simple distribution:\")\n",
    "purpose_counts = df_clean['purpose_simple'].value_counts().sort_index()\n",
    "purpose_distribution = []\n",
    "for code, count in purpose_counts.items():\n",
    "    purpose_line = f\"{code} ({purpose_labels.get(code, 'Unknown')}): {count}\"\n",
    "    purpose_distribution.append(purpose_line)\n",
    "    print(purpose_line)\n",
    "\n",
    "# Create a Word document for output\n",
    "doc = Document()\n",
    "doc.add_heading('Multilevel Truncated Negative Binomial Regression for Length of Stay Analysis', 0)\n",
    "doc.add_heading('Data Preparation and Cleaning', level=1)\n",
    "\n",
    "# Add missing data information\n",
    "doc.add_paragraph('Missing Data Summary:')\n",
    "missing_table = doc.add_table(rows=len(missing_data_summary)+1, cols=2)\n",
    "missing_table.style = 'Table Grid'\n",
    "missing_table.cell(0, 0).text = 'Variable'\n",
    "missing_table.cell(0, 1).text = 'Missing Count'\n",
    "for i, (var, count) in enumerate(missing_data_summary.items(), 1):\n",
    "    missing_table.cell(i, 0).text = str(var)\n",
    "    missing_table.cell(i, 1).text = str(count)\n",
    "\n",
    "doc.add_paragraph('\\nMissing Data Patterns:')\n",
    "patterns_table = doc.add_table(rows=len(missing_patterns_counts)+1, cols=2)\n",
    "patterns_table.style = 'Table Grid'\n",
    "patterns_table.cell(0, 0).text = 'Number of Missing Variables'\n",
    "patterns_table.cell(0, 1).text = 'Count'\n",
    "for i, (pattern, count) in enumerate(missing_patterns_counts.items(), 1):\n",
    "    patterns_table.cell(i, 0).text = str(pattern)\n",
    "    patterns_table.cell(i, 1).text = str(count)\n",
    "\n",
    "# Add Length of Stay histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_hist_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 1: Histogram of Length of Stay (Before Capping)')\n",
    "\n",
    "# Add Capped LOS histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Capped Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_capped_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 2: Histogram of Length of Stay (After Capping at 95th Percentile)')\n",
    "\n",
    "# Add LOS summary statistics\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Summary Statistics 95% Capped', level=2)\n",
    "los_stats_table = doc.add_table(rows=len(los_describe)+1, cols=2)\n",
    "los_stats_table.style = 'Table Grid'\n",
    "los_stats_table.cell(0, 0).text = 'Statistic'\n",
    "los_stats_table.cell(0, 1).text = 'Value'\n",
    "for i, (stat, value) in enumerate(los_describe.items(), 1):\n",
    "    los_stats_table.cell(i, 0).text = str(stat)\n",
    "    los_stats_table.cell(i, 1).text = f\"{value:.4f}\" if isinstance(value, (int, float)) else str(value)\n",
    "\n",
    "# Add Purpose distribution\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Purpose of Visit Distribution', level=2)\n",
    "purpose_table = doc.add_table(rows=len(purpose_distribution)+1, cols=1)\n",
    "purpose_table.style = 'Table Grid'\n",
    "purpose_table.cell(0, 0).text = 'Purpose Category'\n",
    "for i, purpose_text in enumerate(purpose_distribution, 1):\n",
    "    purpose_table.cell(i, 0).text = purpose_text\n",
    "\n",
    "# Fit simple negative binomial regression with continuous variables correctly specified\n",
    "print(\"\\nFitting simple negative binomial regression model...\")\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Negative Binomial Regression Model', level=1)\n",
    "\n",
    "# Define continuous variables and create proper formula\n",
    "continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', \n",
    "                   'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Make sure all continuous variables are properly formatted as numeric\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        df_clean[var] = pd.to_numeric(df_clean[var], errors='coerce')\n",
    "\n",
    "# Create formula with continuous variables properly treated\n",
    "formula_parts = []\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        formula_parts.append(var)\n",
    "\n",
    "# Add categorical variables with proper C() notation\n",
    "categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', \n",
    "                         'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc']\n",
    "\n",
    "for var in categorical_model_vars:\n",
    "    if var in df_clean.columns:\n",
    "        # Use the encoded variable name or the original if available\n",
    "        var_to_use = var\n",
    "        formula_parts.append(f\"C({var_to_use})\")\n",
    "\n",
    "# Combine into final formula\n",
    "formula = 'los_capped ~ ' + ' + '.join(formula_parts)\n",
    "print(f\"Model formula: {formula}\")\n",
    "\n",
    "# Add formula to document\n",
    "doc.add_paragraph(f\"Model formula: {formula}\")\n",
    "\n",
    "# Drop rows with missing values in formula variables\n",
    "##formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "df_clean_nb = df_clean[formula_vars].dropna()\n",
    "df_clean_nb = df_clean_nb.reset_index(drop=True)\n",
    "print(f\"Number of rows in df_clean_nb after dropping missing values: {len(df_clean_nb)}\")\n",
    "\n",
    "\n",
    "# Fit negative binomial model\n",
    "nb_model = smf.glm(formula=formula, \n",
    "                  data=df_clean_nb, \n",
    "                  family=sm.families.NegativeBinomial(link=sm.families.links.log()))\n",
    "\n",
    "try:\n",
    "    nb_results = nb_model.fit()\n",
    "    print(\"\\nNegative Binomial Regression Results:\")\n",
    "    summary_text = str(nb_results.summary())\n",
    "    print(summary_text)\n",
    "    \n",
    "    # Add model summary to document\n",
    "    #doc.add_paragraph('\\nModel Summary:')\n",
    "    summary_paragraph_neg = doc.add_paragraph()\n",
    "    summary_run_neg = summary_paragraph_neg.add_run(summary_text)\n",
    "    summary_run_neg.font.name = 'Courier New'  # Use monospace font\n",
    "    #for line in summary_text.split('\\n'):\n",
    "        #doc.add_paragraph(line)\n",
    "    \n",
    "    # Convert coefficients to incident rate ratios (IRR)\n",
    "    print(\"\\nIncident Rate Ratios (IRR):\")\n",
    "    irr = np.exp(nb_results.params)\n",
    "    irr_conf = np.exp(nb_results.conf_int())\n",
    "    irr_df = pd.DataFrame({'IRR': irr, 'Lower CI': irr_conf[0], 'Upper CI': irr_conf[1], \n",
    "                          'P-value': nb_results.pvalues})\n",
    "    print(irr_df)\n",
    "    \n",
    "    # Add IRR table to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Incident Rate Ratios (IRR)', level=2)\n",
    "    irr_table = doc.add_table(rows=len(irr_df)+1, cols=5)\n",
    "    irr_table.style = 'Table Grid'\n",
    "    irr_table.cell(0, 0).text = 'Variable'\n",
    "    irr_table.cell(0, 1).text = 'IRR'\n",
    "    irr_table.cell(0, 2).text = 'Lower CI'\n",
    "    irr_table.cell(0, 3).text = 'Upper CI'\n",
    "    irr_table.cell(0, 4).text = 'P-value'\n",
    "    \n",
    "    for i, (var, row) in enumerate(irr_df.iterrows(), 1):\n",
    "        irr_table.cell(i, 0).text = str(var)\n",
    "        irr_table.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "        irr_table.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "        irr_table.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "        irr_table.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "    \n",
    "    \n",
    "    # Predictions and diagnostics\n",
    "    df_clean_nb['predicted'] = nb_results.predict()\n",
    "    df_clean_nb['residuals'] = df_clean_nb['los_capped'] - df_clean_nb['predicted']\n",
    "    \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_clean_nb['predicted'], df_clean_nb['residuals'], alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.tight_layout()\n",
    "    residuals_img = BytesIO()\n",
    "    plt.savefig(residuals_img, format='png')\n",
    "    residuals_img.seek(0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Add residuals plot to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Diagnostics', level=2)\n",
    "    doc.add_picture(residuals_img, width=Inches(6))\n",
    "    doc.add_paragraph('Figure 3: Residuals Plot')\n",
    "    \n",
    "    # Check for heterogeneity across states if us_state is in the data\n",
    "    if 'us_state_enc' in df_clean_nb.columns or 'us_state' in df_clean_nb.columns:\n",
    "        state_var = 'us_state_enc' if 'us_state_enc' in df_clean_nb.columns else 'us_state'\n",
    "        state_means = df_clean_nb.groupby(state_var)['los_capped'].mean().sort_values()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        state_means.plot(kind='bar')\n",
    "        plt.xlabel('State')\n",
    "        plt.ylabel('Average Length of Stay')\n",
    "        plt.title('Mean Length of Stay by State')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        los_by_state_img = BytesIO()\n",
    "        plt.savefig(los_by_state_img, format='png')\n",
    "        los_by_state_img.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Add state analysis to document\n",
    "        doc.add_paragraph('\\n')\n",
    "        doc.add_heading('State Analysis', level=2)\n",
    "        doc.add_picture(los_by_state_img, width=Inches(6))\n",
    "        doc.add_paragraph('Figure 4: Mean Length of Stay by State')\n",
    "    \n",
    "    # Approximated Multilevel Model\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Approximated Multilevel Model', level=1)\n",
    "    doc.add_paragraph('Using MixedLM to approximate a multilevel model with random effects for states.')\n",
    "    \n",
    "    # Debugging: Check df_clean_nb and the condition\n",
    "    print(\"Columns in df_clean_nb:\", df_clean_nb.columns.tolist())\n",
    "    print(\"Checking if 'us_state_enc' is in df_clean_nb.columns:\", 'us_state_enc' in df_clean_nb.columns)\n",
    "\n",
    "    # Update variable lists\n",
    "    continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_unemployment']\n",
    "    categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc','us_state_enc', 'month_travel']\n",
    "\n",
    "    \n",
    "\n",
    "    # Check if us_state variable exists for multilevel modeling\n",
    "    if 'us_state_enc' in df_clean_nb.columns:\n",
    "        # For demonstration, we'll use a linear mixed model as an approximation\n",
    "        # Prepare model variables\n",
    "        \n",
    "        # Ensure no missing values in variables used for mixed effects model\n",
    "        model_vars = ['los_capped'] + continuous_vars + categorical_model_vars \n",
    "        df_clean_model = df_clean_nb[model_vars].dropna()\n",
    "\n",
    "        df_clean_model = df_clean_model.reset_index(drop=True)\n",
    "\n",
    "        df_clean_model_old= df_clean_model.copy()\n",
    "\n",
    "        # Remove rows where sex_enc is -1\n",
    "        df_clean_model = df_clean_model[df_clean_model['sex_enc'] != -1]\n",
    "        # Remove rows where age > 100\n",
    "        df_clean_model = df_clean_model[df_clean_model['age'] <= 100]\n",
    "        # Remove rows where marital_status_enc is -1\n",
    "        df_clean_model = df_clean_model[df_clean_model['marital_status_enc'] != -1]\n",
    "        \n",
    "        y = df_clean_model['los_capped']\n",
    "        \n",
    "        # Create X matrix for fixed effects\n",
    "        X_vars = []\n",
    "        for var in continuous_vars:\n",
    "            if var in df_clean_model.columns:\n",
    "                X_vars.append(var)\n",
    "        \n",
    "        X = df_clean_model[X_vars].copy()\n",
    "        \n",
    "        # Add categorical variables (one-hot encoded)\n",
    "        for var in categorical_model_vars:\n",
    "            if var in df_clean_model.columns and var != 'us_state_enc':  # Exclude the grouping variable\n",
    "                dummies = pd.get_dummies(df_clean_model[var], prefix=var, drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "        \n",
    "        # Add intercept\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        X=X.astype(float)\n",
    "        print(\"X dtypes after converting to float:\")\n",
    "        print(X.dtypes)\n",
    "\n",
    "        #Create new X's which will be simplified i.e. no multicollinearity\n",
    "        X_simplified = X.copy()\n",
    "        # Drop columns 'distance_miles' and 'state_unemployment' from X\n",
    "        X_simplified = X_simplified.drop(columns=['distance_miles', 'state_unemployment'])\n",
    "        \n",
    "        # Define groups for random effects\n",
    "        groups = df_clean_model['us_state_enc']\n",
    "\n",
    "        print(f\"Length of df_clean_model: {len(df_clean_model)}\")\n",
    "        print(f\"Length of y: {len(y)}\")\n",
    "        print(f\"Number of rows in X: {X.shape[0]}\")\n",
    "        print(f\"Length of groups: {len(groups)}\")\n",
    "\n",
    "        if len(y) != X.shape[0] or len(y) != len(groups):\n",
    "            print('Length mismatch between y, X, and groups. Check data preparation.')\n",
    "            print(f\"y length:{len(y)}\")\n",
    "            print(f\"X rows: {X.shape[0]}\")\n",
    "            print(f\"groups length: {len(groups)}\")\n",
    "            # Check for NaN values in X\n",
    "            print(\"NaN counts in X columns:\")\n",
    "            print(X.isnull().sum())\n",
    "            raise ValueError(\"Lengths of y, X, and groups do not match!\")\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        # Fit mixed effects model\n",
    "        mixed_model = MixedLM(y, X, groups)\n",
    "        try:\n",
    "            mixed_results = mixed_model.fit()\n",
    "            mixed_summary = str(mixed_results.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary:')\n",
    "            summary_paragraph = doc.add_paragraph()\n",
    "            summary_run = summary_paragraph.add_run(mixed_summary)\n",
    "            summary_run.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var = mixed_results.cov_re.iloc[0, 0]\n",
    "            residual_var = mixed_results.scale\n",
    "            icc = state_var / (state_var + residual_var)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model:\")\n",
    "            irr_mixed = np.exp(mixed_results.params)\n",
    "            irr_conf_mixed = np.exp(mixed_results.conf_int())\n",
    "            irr_df_mixed = pd.DataFrame({'IRR': irr_mixed, 'Lower CI': irr_conf_mixed[0], 'Upper CI': irr_conf_mixed[1], \n",
    "                                'P-value': mixed_results.pvalues})\n",
    "            print(irr_df_mixed)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted'] = mixed_results.fittedvalues\n",
    "            df_clean_model['residuals'] = mixed_results.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted'], df_clean_model['residuals'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img, format='png')\n",
    "            residuals_vs_fitted_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 4: Residuals vs Fitted Values')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img = BytesIO()\n",
    "            plt.savefig(qq_plot_img, format='png')\n",
    "            qq_plot_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 5: Q-Q Plot of Residuals')\n",
    "\n",
    "            # Fit a simple linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat = -2 * (ols_results.llf - mixed_results.llf)\n",
    "            p_value = stats.chi2.sf(lr_stat, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects: Statistic = {lr_stat:.2f}, P-value = {p_value:.4f}')\n",
    "\n",
    "\n",
    "            # Pseudo-R² (McFadden's R² approximation)\n",
    "            null_model = smf.mixedlm(\"los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results = null_model.fit()\n",
    "            pseudo_r2 = 1 - (mixed_results.llf / null_results.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R² (McFadden): {pseudo_r2:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Check VIF for continuous variables\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            X_continuous = X[[col for col in X.columns if col != 'const']]  # Exclude intercept\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"Variable\"] = X_continuous.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_continuous.values, i) for i in range(X_continuous.shape[1])]\n",
    "            print(\"VIF for continuous and dummy variables:\")\n",
    "            print(vif_data)\n",
    "            doc.add_paragraph('\\nVariance Inflation Factor (VIF) for Continuous and Categorical Variables:')\n",
    "            vif_table = doc.add_table(rows=len(vif_data)+1, cols=2)\n",
    "            vif_table.style = 'Table Grid'\n",
    "            vif_table.cell(0, 0).text = 'Variable'\n",
    "            vif_table.cell(0, 1).text = 'VIF'\n",
    "            for i, (var, vif) in enumerate(zip(vif_data[\"Variable\"], vif_data[\"VIF\"]), 1):\n",
    "                vif_table.cell(i, 0).text = str(var)\n",
    "                vif_table.cell(i, 1).text = f\"{vif:.4f}\"\n",
    "            doc.add_paragraph('VIF values above 10 indicate potential multicollinearity issues.')\n",
    "        except ValueError as ve:\n",
    "            error_msg = f\"ValueError in mixed model fitting: {str(ve)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        except RuntimeError as re:\n",
    "            error_msg = f\"RuntimeError in mixed model fitting: {str(re)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")    \n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        \n",
    "        #New mixed effects model starts here this one is a simpler version\n",
    "        \n",
    "\n",
    "        # Fit mixed effects model with fewer variables\n",
    "        mixed_model_simple = MixedLM(y, X_simplified, groups)\n",
    "        try:\n",
    "            mixed_results_simple = mixed_model_simple.fit()\n",
    "            mixed_summary_simple = str(mixed_results_simple.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary_simple)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary with fewer variables:')\n",
    "            summary_paragraph_simple = doc.add_paragraph()\n",
    "            summary_run_simple = summary_paragraph_simple.add_run(mixed_summary_simple)\n",
    "            summary_run_simple.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components with fewer variables:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results_simple.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results_simple.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var_simple = mixed_results_simple.cov_re.iloc[0, 0]\n",
    "            residual_var_simple = mixed_results_simple.scale\n",
    "            icc_simple = state_var_simple / (state_var_simple + residual_var_simple)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model:\")\n",
    "            irr_mixed_simple = np.exp(mixed_results_simple.params)\n",
    "            irr_conf_mixed_simple = np.exp(mixed_results_simple.conf_int())\n",
    "            irr_df_mixed_simple = pd.DataFrame({'IRR': irr_mixed_simple, 'Lower CI': irr_conf_mixed_simple[0], 'Upper CI': irr_conf_mixed_simple[1], \n",
    "                                'P-value': mixed_results_simple.pvalues})\n",
    "            print(irr_df_mixed_simple)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed_simple)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed_simple.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted_simple'] = mixed_results_simple.fittedvalues\n",
    "            df_clean_model['residuals_simple'] = mixed_results_simple.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted_simple'], df_clean_model['residuals_simple'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img_simple = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img_simple, format='png')\n",
    "            residuals_vs_fitted_img_simple.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img_simple, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 5: Residuals vs Fitted Values for Simpler Model')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals_simple'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals Simpler Model')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img_simple = BytesIO()\n",
    "            plt.savefig(qq_plot_img_simple, format='png')\n",
    "            qq_plot_img_simple.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img_simple, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 6: Q-Q Plot of Residuals with fewer variables')\n",
    "\n",
    "            # Fit a simple linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat_simple = -2 * (ols_results.llf - mixed_results_simple.llf)\n",
    "            p_value_simple = stats.chi2.sf(lr_stat_simple, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects with Simple Model: Statistic = {lr_stat_simple:.2f}, P-value = {p_value_simple:.4f}')\n",
    "\n",
    "\n",
    "            # Pseudo-R² (McFadden's R² approximation)\n",
    "            null_model_simple = smf.mixedlm(\"los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results_simple = null_model_simple.fit()\n",
    "            pseudo_r2_simple = 1 - (mixed_results_simple.llf / null_results_simple.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R² (McFadden) fewer variables: {pseudo_r2_simple:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Check VIF for continuous variables\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            X_continuous_simple = X_simplified[[col for col in X_simplified.columns if col != 'const']]  # Exclude intercept\n",
    "            vif_data_simple = pd.DataFrame()\n",
    "            vif_data_simple[\"Variable\"] = X_continuous_simple.columns\n",
    "            vif_data_simple[\"VIF\"] = [variance_inflation_factor(X_continuous_simple.values, i) for i in range(X_continuous_simple.shape[1])]\n",
    "            print(\"VIF for continuous and dummy variables with fewer variables:\")\n",
    "            print(vif_data_simple)\n",
    "            doc.add_paragraph('\\nVariance Inflation Factor (VIF) for Continuous and Categorical Variables with fewer variables:')\n",
    "            vif_table = doc.add_table(rows=len(vif_data_simple)+1, cols=2)\n",
    "            vif_table.style = 'Table Grid'\n",
    "            vif_table.cell(0, 0).text = 'Variable'\n",
    "            vif_table.cell(0, 1).text = 'VIF'\n",
    "            for i, (var, vif) in enumerate(zip(vif_data_simple[\"Variable\"], vif_data_simple[\"VIF\"]), 1):\n",
    "                vif_table.cell(i, 0).text = str(var)\n",
    "                vif_table.cell(i, 1).text = f\"{vif:.4f}\"\n",
    "            doc.add_paragraph('VIF values above 10 indicate potential multicollinearity issues.')\n",
    "        except ValueError as ve:\n",
    "            error_msg = f\"ValueError in mixed model fitting: {str(ve)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        except RuntimeError as re:\n",
    "            error_msg = f\"RuntimeError in mixed model fitting: {str(re)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")    \n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        \n",
    "        #second mixed effects model ends here\n",
    "\n",
    "        #Third mixed effects model with log transformations\n",
    "        # Log transformations will address issues with hetroscedasticity and also model fit\n",
    "\n",
    "        #Step 1: Log transform length of stay but only if it was non zero\n",
    "        df_clean_model['log_los_capped'] = np.where(df_clean_model['los_capped'] > 0, np.log(df_clean_model['los_capped']), 0)\n",
    "                                   \n",
    "\n",
    "        #Step 2: Log transform the continuous variables\n",
    "            # Log-transform age (showed high VIF and potential non-linearity)\n",
    "        df_clean_model['log_age'] = np.log1p(df_clean_model['age'])\n",
    "\n",
    "             # Log-transform distance_miles (potential non-linear effect on length of stay)\n",
    "        df_clean_model['log_distance'] = np.log1p(df_clean_model['distance_miles'])\n",
    "\n",
    "            # log transform others such as immigrant_population, import_from_slu and state_percapita_income\n",
    "        \n",
    "        df_clean_model['log_immigrant_population'] = np.log1p(df_clean_model['immigrant_population'])\n",
    "        df_clean_model['log_import_from_slu'] = np.log1p(df_clean_model['import_from_slu'])\n",
    "        #df_clean_model['log_state_percapita_income'] = np.log1p(df_clean_model['state_percapita_income'])\n",
    "        df_clean_model['log_state_unemployment'] = np.log1p(df_clean_model['state_unemployment'])\n",
    "\n",
    "        #With these transformations, now we set new X's and y's for the mixed effects model\n",
    "        y_log = df_clean_model['log_los_capped']\n",
    "        # Create X matrix for fixed effects\n",
    "        X_log= X.copy()\n",
    "\n",
    "        #Drop the original continuous variables\n",
    "        X_log = X_log.drop(columns=['age', 'distance_miles', 'immigrant_population', 'import_from_slu',  'state_unemployment'])\n",
    "                                    \n",
    "        # Add log-transformed continuous variables\n",
    "        X_log['log_age'] = df_clean_model['log_age']**3\n",
    "        X_log['log_distance'] = df_clean_model['log_distance']**3\n",
    "        X_log['log_immigrant_population'] = df_clean_model['log_immigrant_population']**2\n",
    "        X_log['log_import_from_slu'] = df_clean_model['log_import_from_slu']**2\n",
    "        #X_log['log_state_percapita_income'] = df_clean_model['log_state_percapita_income']\n",
    "        X_log['log_state_unemployment'] = df_clean_model['log_state_unemployment']**2 \n",
    "        \n",
    "    # Fit mixed effects model with log-transformed variables\n",
    "        mixed_model_log = MixedLM(y_log, X_log, groups)\n",
    "        try:\n",
    "            mixed_results_log = mixed_model_log.fit()\n",
    "            mixed_summary_log = str(mixed_results_log.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results With Log Transformations:\")\n",
    "            print(mixed_summary_log)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary With Log Transformations:')\n",
    "            summary_paragraph_log = doc.add_paragraph()\n",
    "            summary_run_log = summary_paragraph_log.add_run(mixed_summary_log)\n",
    "            summary_run_log.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components With Log Transformations:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results_log.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results_log.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var_log = mixed_results_log.cov_re.iloc[0, 0]\n",
    "            residual_var_log = mixed_results_log.scale\n",
    "            icc_log = state_var_log / (state_var_log + residual_var_log)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model With Log Transformations:\")\n",
    "            irr_mixed_log = np.exp(mixed_results_log.params)\n",
    "            irr_conf_mixed_log = np.exp(mixed_results_log.conf_int())\n",
    "            irr_df_mixed_log = pd.DataFrame({'IRR': irr_mixed_log, 'Lower CI': irr_conf_mixed_log[0], 'Upper CI': irr_conf_mixed_log[1], \n",
    "                                'P-value': mixed_results_log.pvalues})\n",
    "            print(irr_df_mixed_log)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model With Log Transformations', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed_log)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed_log.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted_log'] = mixed_results_log.fittedvalues\n",
    "            df_clean_model['residuals_log'] = mixed_results_log.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted_log'], df_clean_model['residuals_log'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img_log = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img_log, format='png')\n",
    "            residuals_vs_fitted_img_log.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img_log, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 8: Residuals vs Fitted Values With Log Transformations')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals_log'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals With Log Transformations')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img_log = BytesIO()\n",
    "            plt.savefig(qq_plot_img_log, format='png')\n",
    "            qq_plot_img_log.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img_log, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 9: Q-Q Plot of Residuals With Log Transformations')\n",
    "\n",
    "            # Fit a log linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat_log = -2 * (ols_results.llf - mixed_results_log.llf)\n",
    "            p_value_log = stats.chi2.sf(lr_stat_log, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects with log Model: Statistic = {lr_stat_log:.2f}, P-value = {p_value_log:.4f}')\n",
    "\n",
    "\n",
    "            # Pseudo-R² (McFadden's R² approximation)\n",
    "            null_model_log = smf.mixedlm(\"log_los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results_log = null_model_log.fit()\n",
    "            pseudo_r2_log = 1 - (mixed_results_log.llf / null_results_log.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R² (McFadden) With Log Transformations: {pseudo_r2_log:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Check VIF for continuous variables\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            X_continuous_log = X_log[[col for col in X_log.columns if col != 'const']]  # Exclude intercept\n",
    "            vif_data_log = pd.DataFrame()\n",
    "            vif_data_log[\"Variable\"] = X_continuous_log.columns\n",
    "            vif_data_log[\"VIF\"] = [variance_inflation_factor(X_continuous_log.values, i) for i in range(X_continuous_log.shape[1])]\n",
    "            print(\"VIF for continuous and dummy variables With Log Transformations:\")\n",
    "            print(vif_data_log)\n",
    "            doc.add_paragraph('\\nVariance Inflation Factor (VIF) for Continuous and Categorical Variables With Log Transformations:')\n",
    "            vif_table = doc.add_table(rows=len(vif_data_log)+1, cols=2)\n",
    "            vif_table.style = 'Table Grid'\n",
    "            vif_table.cell(0, 0).text = 'Variable'\n",
    "            vif_table.cell(0, 1).text = 'VIF'\n",
    "            for i, (var, vif) in enumerate(zip(vif_data_log[\"Variable\"], vif_data_log[\"VIF\"]), 1):\n",
    "                vif_table.cell(i, 0).text = str(var)\n",
    "                vif_table.cell(i, 1).text = f\"{vif:.4f}\"\n",
    "            doc.add_paragraph('VIF values above 10 indicate potential multicollinearity issues.')\n",
    "        except ValueError as ve:\n",
    "            error_msg = f\"ValueError in mixed model fitting: {str(ve)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        except RuntimeError as re:\n",
    "            error_msg = f\"RuntimeError in mixed model fitting: {str(re)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")    \n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "\n",
    "\n",
    "        #Log transform model ends here\n",
    "    else:\n",
    "        no_state_msg = \"State variable not found for multilevel modeling.\"\n",
    "        print(no_state_msg)\n",
    "        doc.add_paragraph(no_state_msg)\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"\\nError in model fitting: {str(e)}\"\n",
    "    print(error_msg)\n",
    "    doc.add_paragraph(error_msg)\n",
    "    doc.add_paragraph(\"You may need to check your data or consider using a different modeling approach.\")\n",
    "\n",
    "# Save the Word document\n",
    "print(\"\\nPlease select where to save the Word document...\")\n",
    "doc_path = select_file(\n",
    "    \"Save Analysis Report As\", \n",
    "    [(\"Word Document\", \"*.docx\"), (\"All files\", \"*.*\")],\n",
    "    save=True\n",
    ")\n",
    "\n",
    "if doc_path:\n",
    "    if not doc_path.endswith('.docx'):\n",
    "        doc_path += '.docx'\n",
    "    doc.save(doc_path)\n",
    "    print(f\"Analysis report saved to: {doc_path}\")\n",
    "else:\n",
    "    print(\"Document not saved as no location was selected.\")\n",
    "\n",
    "print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlslu2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
