{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families.family import NegativeBinomial\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from scipy import stats\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from io import BytesIO\n",
    "import statsmodels.discrete.discrete_model as discrete\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "def select_file(title, file_types, save=False):\n",
    "    \"\"\"Allow user to select a file\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    try:\n",
    "        if save:\n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types,\n",
    "                defaultextension=file_types[0][1]\n",
    "            )\n",
    "        else:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types\n",
    "            )\n",
    "    finally:\n",
    "        root.destroy()\n",
    "    \n",
    "    return file_path if file_path else None\n",
    "\n",
    "# Allow user to select input file\n",
    "print(\"Please select the input Excel file...\")\n",
    "file_path = select_file(\n",
    "    \"Select Excel Data File\", \n",
    "    [(\"Excel files\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "if not file_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Import the data\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"Sheet\")\n",
    "\n",
    "# Setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Encode categorical variables if not already encoded\n",
    "categorical_vars = ['sex', 'marital_status', 'employment_status', 'purpose', 'accomd_type', 'us_state']\n",
    "encoded_vars = {}\n",
    "\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        # Check if variable is already numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df[var]):\n",
    "            new_var = f\"{var}_enc\"\n",
    "            df[new_var] = pd.Categorical(df[var]).codes\n",
    "            encoded_vars[var] = new_var\n",
    "        else:\n",
    "            encoded_vars[var] = var\n",
    "\n",
    "# Set the truncation point for los (assuming truncation at 0)\n",
    "df['los_trunc'] = df['los'].copy()\n",
    "df.loc[df['los_trunc'] <= 0, 'los_trunc'] = np.nan\n",
    "\n",
    "# Check for missing data\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing_data_summary = df.isnull().sum()\n",
    "print(missing_data_summary)\n",
    "\n",
    "print(\"\\nMissing data patterns:\")\n",
    "missing_patterns = df.isnull().sum(axis=1)\n",
    "missing_patterns_counts = missing_patterns.value_counts().sort_index()\n",
    "print(missing_patterns_counts)\n",
    "\n",
    "# Visualize los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['los_trunc'], discrete=True)\n",
    "plt.title('Histogram of Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_hist_img = BytesIO()\n",
    "plt.savefig(los_hist_img, format='png')\n",
    "los_hist_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Summarize los by purpose\n",
    "purpose_stats = None\n",
    "if 'purpose_enc' in df.columns:\n",
    "    print(\"\\nLength of stay by purpose:\")\n",
    "    purpose_stats = df.groupby('purpose_enc')['los_trunc'].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    print(purpose_stats)\n",
    "\n",
    "# Detailed summary of los_trunc\n",
    "print(\"\\nDetailed summary of length of stay:\")\n",
    "los_describe = df['los_trunc'].describe(percentiles=[.25, .5, .75, .90, .95, .99])\n",
    "print(los_describe)\n",
    "\n",
    "# Cleaning process\n",
    "# Step 1: Drop missing datapoints for key variables\n",
    "key_vars = ['los', 'immigrant_population', 'import_from_slu', 'age', \n",
    "            encoded_vars.get('sex', 'sex_enc'), \n",
    "            encoded_vars.get('marital_status', 'marital_status_enc'), \n",
    "            encoded_vars.get('employment_status', 'employment_status_enc'), \n",
    "            'distance_miles', \n",
    "            encoded_vars.get('purpose', 'purpose_enc'), \n",
    "            encoded_vars.get('accomd_type', 'accomd_type_enc'), \n",
    "            'month_travel', 'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Count missing values per row for key variables\n",
    "df['missing'] = df[key_vars].isnull().sum(axis=1)\n",
    "print(\"\\nNumber of missing values per observation:\")\n",
    "missing_values_count = df['missing'].value_counts().sort_index()\n",
    "print(missing_values_count)\n",
    "\n",
    "# Drop observations with missing values in key variables\n",
    "df_clean = df[df['missing'] == 0].drop('missing', axis=1)\n",
    "print(f\"\\nRemaining observations after dropping missing values: {len(df_clean)}\")\n",
    "\n",
    "# Step 2: Drop outliers in length of stay\n",
    "los_p95 = np.percentile(df_clean['los_trunc'].dropna(), 95)\n",
    "df_clean['los_capped'] = df_clean['los_trunc'].copy()\n",
    "df_clean.loc[df_clean['los_capped'] > los_p95, 'los_capped'] = los_p95\n",
    "\n",
    "df_clean = df_clean[df_clean['los_trunc'] <= los_p95]\n",
    "print(f\"After filtering to 95th percentile, remaining observations: {len(df_clean)}\")\n",
    "\n",
    "\n",
    "# Visualize the capped los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['los_capped'], discrete=True)\n",
    "plt.title('Histogram of Capped Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_capped_img = BytesIO()\n",
    "plt.savefig(los_capped_img, format='png')\n",
    "los_capped_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Clean up the purpose of trip column\n",
    "# Create a new simplified purpose variable\n",
    "purpose_mapping = {\n",
    "    1: 1,  # BUSINESS/MEETING -> Business\n",
    "    2: 1,  # CONVENTION -> Business\n",
    "    3: 1,  # CREW -> Business\n",
    "    5: 2,  # EVENT -> Events\n",
    "    6: 2,  # EVENTS -> Events\n",
    "    7: 4,  # HONEYMOON -> Pleasure\n",
    "    8: 5,  # INTRANSIT PASSEN -> Other\n",
    "    9: 5,  # OTHER -> Other\n",
    "    10: 4, # PLEASURE/HOLIDAY -> Pleasure\n",
    "    11: 5, # RESIDENT -> Other\n",
    "    12: 2, # SAINT LUCIA CARN -> Events\n",
    "    13: 2, # SAINT LUCIA JAZZ -> Events\n",
    "    14: 5, # SPORTS -> Other\n",
    "    15: 5, # STUDY -> Other\n",
    "    16: 5, # VISITING FRIENDS -> Other\n",
    "    17: 3, # WEDDING -> Wedding\n",
    "    18: 4, # pLEASURE/HOLIDAY -> Pleasure\n",
    "    4: 5,  # CRICKET -> Other\n",
    "}\n",
    "\n",
    "purpose_labels = {\n",
    "    1: \"Business\",\n",
    "    2: \"Events\",\n",
    "    3: \"Wedding\",\n",
    "    4: \"Pleasure\",\n",
    "    5: \"Other\"\n",
    "}\n",
    "\n",
    "# Add the simplified purpose variable\n",
    "purpose_enc_col = encoded_vars.get('purpose', 'purpose_enc')\n",
    "df_clean['purpose_simple'] = df_clean[purpose_enc_col].map(purpose_mapping)\n",
    "\n",
    "# Check the new variable\n",
    "print(\"\\nPurpose simple distribution:\")\n",
    "purpose_counts = df_clean['purpose_simple'].value_counts().sort_index()\n",
    "purpose_distribution = []\n",
    "for code, count in purpose_counts.items():\n",
    "    purpose_line = f\"{code} ({purpose_labels.get(code, 'Unknown')}): {count}\"\n",
    "    purpose_distribution.append(purpose_line)\n",
    "    print(purpose_line)\n",
    "\n",
    "# Create a Word document for output\n",
    "doc = Document()\n",
    "doc.add_heading('Multilevel Truncated Negative Binomial Regression for Length of Stay Analysis', 0)\n",
    "doc.add_heading('Data Preparation and Cleaning', level=1)\n",
    "\n",
    "# Add missing data information\n",
    "doc.add_paragraph('Missing Data Summary:')\n",
    "missing_table = doc.add_table(rows=len(missing_data_summary)+1, cols=2)\n",
    "missing_table.style = 'Table Grid'\n",
    "missing_table.cell(0, 0).text = 'Variable'\n",
    "missing_table.cell(0, 1).text = 'Missing Count'\n",
    "for i, (var, count) in enumerate(missing_data_summary.items(), 1):\n",
    "    missing_table.cell(i, 0).text = str(var)\n",
    "    missing_table.cell(i, 1).text = str(count)\n",
    "\n",
    "doc.add_paragraph('\\nMissing Data Patterns:')\n",
    "patterns_table = doc.add_table(rows=len(missing_patterns_counts)+1, cols=2)\n",
    "patterns_table.style = 'Table Grid'\n",
    "patterns_table.cell(0, 0).text = 'Number of Missing Variables'\n",
    "patterns_table.cell(0, 1).text = 'Count'\n",
    "for i, (pattern, count) in enumerate(missing_patterns_counts.items(), 1):\n",
    "    patterns_table.cell(i, 0).text = str(pattern)\n",
    "    patterns_table.cell(i, 1).text = str(count)\n",
    "\n",
    "# Add Length of Stay histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_hist_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 1: Histogram of Length of Stay (Before Capping)')\n",
    "\n",
    "# Add Capped LOS histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Capped Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_capped_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 2: Histogram of Length of Stay (After Capping at 95th Percentile)')\n",
    "\n",
    "# Add LOS summary statistics\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Summary Statistics 95% Capped', level=2)\n",
    "los_stats_table = doc.add_table(rows=len(los_describe)+1, cols=2)\n",
    "los_stats_table.style = 'Table Grid'\n",
    "los_stats_table.cell(0, 0).text = 'Statistic'\n",
    "los_stats_table.cell(0, 1).text = 'Value'\n",
    "for i, (stat, value) in enumerate(los_describe.items(), 1):\n",
    "    los_stats_table.cell(i, 0).text = str(stat)\n",
    "    los_stats_table.cell(i, 1).text = f\"{value:.4f}\" if isinstance(value, (int, float)) else str(value)\n",
    "\n",
    "# Add Purpose distribution\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Purpose of Visit Distribution', level=2)\n",
    "purpose_table = doc.add_table(rows=len(purpose_distribution)+1, cols=1)\n",
    "purpose_table.style = 'Table Grid'\n",
    "purpose_table.cell(0, 0).text = 'Purpose Category'\n",
    "for i, purpose_text in enumerate(purpose_distribution, 1):\n",
    "    purpose_table.cell(i, 0).text = purpose_text\n",
    "\n",
    "# Fit simple negative binomial regression with continuous variables correctly specified\n",
    "print(\"\\nFitting simple negative binomial regression model...\")\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Negative Binomial Regression Model', level=1)\n",
    "\n",
    "# Define continuous variables and create proper formula\n",
    "continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', \n",
    "                   'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Make sure all continuous variables are properly formatted as numeric\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        df_clean[var] = pd.to_numeric(df_clean[var], errors='coerce')\n",
    "\n",
    "# Create formula with continuous variables properly treated\n",
    "formula_parts = []\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        formula_parts.append(var)\n",
    "\n",
    "# Add categorical variables with proper C() notation\n",
    "categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', \n",
    "                         'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc']\n",
    "\n",
    "for var in categorical_model_vars:\n",
    "    if var in df_clean.columns:\n",
    "        # Use the encoded variable name or the original if available\n",
    "        var_to_use = var\n",
    "        formula_parts.append(f\"C({var_to_use})\")\n",
    "\n",
    "# Combine into final formula\n",
    "formula = 'los_capped ~ ' + ' + '.join(formula_parts)\n",
    "print(f\"Model formula: {formula}\")\n",
    "\n",
    "# Add formula to document\n",
    "doc.add_paragraph(f\"Model formula: {formula}\")\n",
    "\n",
    "# Drop rows with missing values in formula variables\n",
    "##formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "df_clean_nb = df_clean[formula_vars].dropna()\n",
    "df_clean_nb = df_clean_nb.reset_index(drop=True)\n",
    "print(f\"Number of rows in df_clean_nb after dropping missing values: {len(df_clean_nb)}\")\n",
    "\n",
    "\n",
    "# Fit negative binomial model\n",
    "nb_model = smf.glm(formula=formula, \n",
    "                  data=df_clean_nb, \n",
    "                  family=sm.families.NegativeBinomial(link=sm.families.links.log()))\n",
    "\n",
    "try:\n",
    "    nb_results = nb_model.fit()\n",
    "    print(\"\\nNegative Binomial Regression Results:\")\n",
    "    summary_text = str(nb_results.summary())\n",
    "    print(summary_text)\n",
    "    \n",
    "    # Add model summary to document\n",
    "    #doc.add_paragraph('\\nModel Summary:')\n",
    "    summary_paragraph_neg = doc.add_paragraph()\n",
    "    summary_run_neg = summary_paragraph_neg.add_run(summary_text)\n",
    "    summary_run_neg.font.name = 'Courier New'  # Use monospace font\n",
    "    #for line in summary_text.split('\\n'):\n",
    "        #doc.add_paragraph(line)\n",
    "    \n",
    "    # Convert coefficients to incident rate ratios (IRR)\n",
    "    print(\"\\nIncident Rate Ratios (IRR):\")\n",
    "    irr = np.exp(nb_results.params)\n",
    "    irr_conf = np.exp(nb_results.conf_int())\n",
    "    irr_df = pd.DataFrame({'IRR': irr, 'Lower CI': irr_conf[0], 'Upper CI': irr_conf[1], \n",
    "                          'P-value': nb_results.pvalues})\n",
    "    print(irr_df)\n",
    "    \n",
    "    # Add IRR table to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Incident Rate Ratios (IRR)', level=2)\n",
    "    irr_table = doc.add_table(rows=len(irr_df)+1, cols=5)\n",
    "    irr_table.style = 'Table Grid'\n",
    "    irr_table.cell(0, 0).text = 'Variable'\n",
    "    irr_table.cell(0, 1).text = 'IRR'\n",
    "    irr_table.cell(0, 2).text = 'Lower CI'\n",
    "    irr_table.cell(0, 3).text = 'Upper CI'\n",
    "    irr_table.cell(0, 4).text = 'P-value'\n",
    "    \n",
    "    for i, (var, row) in enumerate(irr_df.iterrows(), 1):\n",
    "        irr_table.cell(i, 0).text = str(var)\n",
    "        irr_table.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "        irr_table.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "        irr_table.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "        irr_table.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "    \n",
    "    \n",
    "    # Predictions and diagnostics\n",
    "    df_clean_nb['predicted'] = nb_results.predict()\n",
    "    df_clean_nb['residuals'] = df_clean_nb['los_capped'] - df_clean_nb['predicted']\n",
    "    \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_clean_nb['predicted'], df_clean_nb['residuals'], alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.tight_layout()\n",
    "    residuals_img = BytesIO()\n",
    "    plt.savefig(residuals_img, format='png')\n",
    "    residuals_img.seek(0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Add residuals plot to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Diagnostics', level=2)\n",
    "    doc.add_picture(residuals_img, width=Inches(6))\n",
    "    doc.add_paragraph('Figure 3: Residuals Plot')\n",
    "    \n",
    "    # Check for heterogeneity across states if us_state is in the data\n",
    "    if 'us_state_enc' in df_clean_nb.columns or 'us_state' in df_clean_nb.columns:\n",
    "        state_var = 'us_state_enc' if 'us_state_enc' in df_clean_nb.columns else 'us_state'\n",
    "        state_means = df_clean_nb.groupby(state_var)['los_capped'].mean().sort_values()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        state_means.plot(kind='bar')\n",
    "        plt.xlabel('State')\n",
    "        plt.ylabel('Average Length of Stay')\n",
    "        plt.title('Mean Length of Stay by State')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        los_by_state_img = BytesIO()\n",
    "        plt.savefig(los_by_state_img, format='png')\n",
    "        los_by_state_img.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Add state analysis to document\n",
    "        doc.add_paragraph('\\n')\n",
    "        doc.add_heading('State Analysis', level=2)\n",
    "        doc.add_picture(los_by_state_img, width=Inches(6))\n",
    "        doc.add_paragraph('Figure 4: Mean Length of Stay by State')\n",
    "    \n",
    "    # Approximated Multilevel Model\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Approximated Multilevel Model', level=1)\n",
    "    doc.add_paragraph('Using MixedLM to approximate a multilevel model with random effects for states.')\n",
    "    \n",
    "    # Debugging: Check df_clean_nb and the condition\n",
    "    print(\"Columns in df_clean_nb:\", df_clean_nb.columns.tolist())\n",
    "    print(\"Checking if 'us_state_enc' is in df_clean_nb.columns:\", 'us_state_enc' in df_clean_nb.columns)\n",
    "\n",
    "# Update variable lists\n",
    "    continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_unemployment']\n",
    "    categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc','us_state_enc', 'month_travel']\n",
    "\n",
    "    # Check if us_state variable exists for multilevel modeling\n",
    "    if 'us_state_enc' in df_clean_nb.columns:\n",
    "        # For demonstration, we'll use a linear mixed model as an approximation\n",
    "        # Prepare model variables\n",
    "        \n",
    "        # Ensure no missing values in variables used for mixed effects model\n",
    "        model_vars = ['los_capped'] + continuous_vars + categorical_model_vars \n",
    "        df_clean_model = df_clean_nb[model_vars].dropna()\n",
    "\n",
    "        df_clean_model = df_clean_model.reset_index(drop=True)\n",
    "        \n",
    "        y = df_clean_model['los_capped']\n",
    "        \n",
    "        # Create X matrix for fixed effects\n",
    "        X_vars = []\n",
    "        for var in continuous_vars:\n",
    "            if var in df_clean_model.columns:\n",
    "                X_vars.append(var)\n",
    "        \n",
    "        X = df_clean_model[X_vars].copy()\n",
    "        \n",
    "        # Add categorical variables (one-hot encoded)\n",
    "        for var in categorical_model_vars:\n",
    "            if var in df_clean_model.columns and var != 'us_state_enc':  # Exclude the grouping variable\n",
    "                dummies = pd.get_dummies(df_clean_model[var], prefix=var, drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "        \n",
    "        # Add intercept\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        X=X.astype(float)\n",
    "        print(\"X dtypes after converting to float:\")\n",
    "        print(X.dtypes)\n",
    "        \n",
    "        # Define groups for random effects\n",
    "        groups = df_clean_model['us_state_enc']\n",
    "\n",
    "        print(f\"Length of df_clean_model: {len(df_clean_model)}\")\n",
    "        print(f\"Length of y: {len(y)}\")\n",
    "        print(f\"Number of rows in X: {X.shape[0]}\")\n",
    "        print(f\"Length of groups: {len(groups)}\")\n",
    "\n",
    "        if len(y) != X.shape[0] or len(y) != len(groups):\n",
    "            print('Length mismatch between y, X, and groups. Check data preparation.')\n",
    "            print(f\"y length:{len(y)}\")\n",
    "            print(f\"X rows: {X.shape[0]}\")\n",
    "            print(f\"groups length: {len(groups)}\")\n",
    "            # Check for NaN values in X\n",
    "            print(\"NaN counts in X columns:\")\n",
    "            print(X.isnull().sum())\n",
    "            raise ValueError(\"Lengths of y, X, and groups do not match!\")\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        # Fit mixed effects model\n",
    "        mixed_model = MixedLM(y, X, groups)\n",
    "        try:\n",
    "            mixed_results = mixed_model.fit()\n",
    "            mixed_summary = str(mixed_results.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary:')\n",
    "            summary_paragraph = doc.add_paragraph()\n",
    "            summary_run = summary_paragraph.add_run(mixed_summary)\n",
    "            summary_run.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var = mixed_results.cov_re.iloc[0, 0]\n",
    "            residual_var = mixed_results.scale\n",
    "            icc = state_var / (state_var + residual_var)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model:\")\n",
    "            irr_mixed = np.exp(mixed_results.params)\n",
    "            irr_conf_mixed = np.exp(mixed_results.conf_int())\n",
    "            irr_df_mixed = pd.DataFrame({'IRR': irr_mixed, 'Lower CI': irr_conf_mixed[0], 'Upper CI': irr_conf_mixed[1], \n",
    "                                'P-value': mixed_results.pvalues})\n",
    "            print(irr_df_mixed)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted'] = mixed_results.fittedvalues\n",
    "            df_clean_model['residuals'] = mixed_results.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted'], df_clean_model['residuals'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img, format='png')\n",
    "            residuals_vs_fitted_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 4: Residuals vs Fitted Values')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img = BytesIO()\n",
    "            plt.savefig(qq_plot_img, format='png')\n",
    "            qq_plot_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 5: Q-Q Plot of Residuals')\n",
    "\n",
    "            # Fit a simple linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat = -2 * (ols_results.llf - mixed_results.llf)\n",
    "            p_value = stats.chi2.sf(lr_stat, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects: Statistic = {lr_stat:.2f}, P-value = {p_value:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Pseudo-R² (McFadden's R² approximation)\n",
    "            null_model = smf.mixedlm(\"los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results = null_model.fit()\n",
    "            pseudo_r2 = 1 - (mixed_results.llf / null_results.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R² (McFadden): {pseudo_r2:.4f}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "    else:\n",
    "        no_state_msg = \"State variable not found for multilevel modeling.\"\n",
    "        print(no_state_msg)\n",
    "        doc.add_paragraph(no_state_msg)\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"\\nError in model fitting: {str(e)}\"\n",
    "    print(error_msg)\n",
    "    doc.add_paragraph(error_msg)\n",
    "    doc.add_paragraph(\"You may need to check your data or consider using a different modeling approach.\")\n",
    "\n",
    "# Save the Word document\n",
    "print(\"\\nPlease select where to save the Word document...\")\n",
    "doc_path = select_file(\n",
    "    \"Save Analysis Report As\", \n",
    "    [(\"Word Document\", \"*.docx\"), (\"All files\", \"*.*\")],\n",
    "    save=True\n",
    ")\n",
    "\n",
    "if doc_path:\n",
    "    if not doc_path.endswith('.docx'):\n",
    "        doc_path += '.docx'\n",
    "    doc.save(doc_path)\n",
    "    print(f\"Analysis report saved to: {doc_path}\")\n",
    "else:\n",
    "    print(\"Document not saved as no location was selected.\")\n",
    "\n",
    "print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
