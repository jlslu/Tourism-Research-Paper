{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the input Excel file...\n",
      "Loading data from: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/1.0 Data cleaning/Final data for model/stata raw data.xlsx\n",
      "\n",
      "Missing data summary:\n",
      "los                         75\n",
      "age                          0\n",
      "sex                         26\n",
      "marital_status              12\n",
      "employment_status          425\n",
      "distance_miles               0\n",
      "purpose                    403\n",
      "accomd_type                  0\n",
      "state_percapita_income       0\n",
      "state_unemployment           0\n",
      "travel_date                  0\n",
      "month_travel                 0\n",
      "import_from_slu              0\n",
      "immigrant_population         0\n",
      "us_state                     0\n",
      "sex_enc                      0\n",
      "marital_status_enc           0\n",
      "employment_status_enc        0\n",
      "purpose_enc                  0\n",
      "accomd_type_enc              0\n",
      "us_state_enc                 0\n",
      "los_trunc                 2178\n",
      "dtype: int64\n",
      "\n",
      "Missing data patterns:\n",
      "0    142227\n",
      "1      2910\n",
      "2       103\n",
      "3         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of stay by purpose:\n",
      "              count        mean  median  min      max          std\n",
      "purpose_enc                                                       \n",
      "-1              389    7.748072     6.0  2.0    373.0    19.536597\n",
      " 0             2131    6.845612     4.0  1.0    372.0    21.176125\n",
      " 1              425    6.334118     5.0  1.0    368.0    18.004622\n",
      " 2              175    7.000000     4.0  1.0    124.0    13.963005\n",
      " 3              432    4.282407     4.0  1.0     17.0     2.203955\n",
      " 4                2    7.000000     7.0  7.0      7.0     0.000000\n",
      " 5              407    6.154791     5.0  2.0     92.0     6.614890\n",
      " 6            22066    6.658253     6.0  1.0    372.0     6.694363\n",
      " 7             1212   69.916667     7.0  1.0  73109.0  2099.927812\n",
      " 8             1361  119.255694     7.0  1.0  73055.0  2799.175773\n",
      " 9           102372    8.927089     6.0  1.0  64986.0   264.902993\n",
      " 10              28    9.857143     7.0  2.0     29.0     6.948031\n",
      " 11            1399    7.987848     7.0  1.0    159.0     7.711945\n",
      " 12             377    6.785146     5.0  1.0    157.0    10.564593\n",
      " 13             177    5.762712     5.0  1.0     42.0     4.328837\n",
      " 14              42   12.214286     7.0  3.0    166.0    24.656208\n",
      " 15            3439   13.221867     8.0  1.0    393.0    25.614415\n",
      " 16            6623    6.179828     5.0  1.0    375.0    14.807467\n",
      " 17               6    6.333333     6.0  6.0      7.0     0.516398\n",
      "\n",
      "Detailed summary of length of stay:\n",
      "count    143063.000000\n",
      "mean         10.035565\n",
      "std         402.763642\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%           6.000000\n",
      "75%           7.000000\n",
      "90%           8.000000\n",
      "95%          10.000000\n",
      "99%          28.000000\n",
      "max       73109.000000\n",
      "Name: los_trunc, dtype: float64\n",
      "\n",
      "Number of missing values per observation:\n",
      "missing\n",
      "0    145166\n",
      "1        75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Remaining observations after dropping missing values: 145166\n",
      "After filtering to 95th percentile, remaining observations: 136252\n",
      "\n",
      "Purpose simple distribution:\n",
      "1.0 (Business): 980\n",
      "2.0 (Events): 22549\n",
      "3.0 (Wedding): 6\n",
      "4.0 (Pleasure): 1104\n",
      "5.0 (Other): 109257\n",
      "\n",
      "Fitting simple negative binomial regression model...\n",
      "Model formula: los_capped ~ immigrant_population + import_from_slu + age + distance_miles + state_percapita_income + state_unemployment + C(sex_enc) + C(marital_status_enc) + C(employment_status_enc) + C(purpose_simple) + C(accomd_type_enc) + C(month_travel) + C(us_state_enc)\n",
      "Number of rows in df_clean_nb after dropping missing values: 132666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative Binomial Regression Results:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             los_capped   No. Observations:               132666\n",
      "Model:                            GLM   Df Residuals:                   132590\n",
      "Model Family:        NegativeBinomial   Df Model:                           75\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -3.7630e+05\n",
      "Date:                Sun, 18 May 2025   Deviance:                       8931.3\n",
      "Time:                        15:06:21   Pearson chi2:                 8.24e+03\n",
      "No. Iterations:                    65   Pseudo R-squ. (CS):           0.007270\n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.4554      0.241      1.891      0.059      -0.016       0.927\n",
      "C(sex_enc)[T.0]                  -0.1144      0.230     -0.498      0.618      -0.564       0.336\n",
      "C(sex_enc)[T.1]                  -0.1037      0.230     -0.452      0.652      -0.554       0.346\n",
      "C(marital_status_enc)[T.0]        0.0600      0.315      0.190      0.849      -0.558       0.678\n",
      "C(marital_status_enc)[T.1]        0.0368      0.316      0.117      0.907      -0.582       0.656\n",
      "C(marital_status_enc)[T.2]        0.0159      0.315      0.051      0.960      -0.602       0.634\n",
      "C(employment_status_enc)[T.0]    -0.0022      0.056     -0.039      0.969      -0.112       0.107\n",
      "C(employment_status_enc)[T.1]     0.0137      0.066      0.208      0.835      -0.115       0.143\n",
      "C(employment_status_enc)[T.2]    -0.0100      0.073     -0.138      0.890      -0.153       0.133\n",
      "C(purpose_simple)[T.2.0]          0.4182      0.037     11.338      0.000       0.346       0.491\n",
      "C(purpose_simple)[T.3.0]          0.3963      0.441      0.899      0.369      -0.468       1.260\n",
      "C(purpose_simple)[T.4.0]          0.2246      0.049      4.600      0.000       0.129       0.320\n",
      "C(purpose_simple)[T.5.0]          0.2817      0.036      7.821      0.000       0.211       0.352\n",
      "C(accomd_type_enc)[T.1]           0.0413      0.016      2.543      0.011       0.009       0.073\n",
      "C(accomd_type_enc)[T.2]           0.0935      0.009     10.082      0.000       0.075       0.112\n",
      "C(month_travel)[T.2]             -0.0132      0.015     -0.877      0.381      -0.043       0.016\n",
      "C(month_travel)[T.3]             -0.0009      0.015     -0.060      0.952      -0.030       0.028\n",
      "C(month_travel)[T.4]             -0.0203      0.015     -1.317      0.188      -0.050       0.010\n",
      "C(month_travel)[T.5]             -0.0188      0.015     -1.265      0.206      -0.048       0.010\n",
      "C(month_travel)[T.6]             -0.0094      0.015     -0.637      0.524      -0.038       0.019\n",
      "C(month_travel)[T.7]              0.0233      0.015      1.582      0.114      -0.006       0.052\n",
      "C(month_travel)[T.8]             -0.0401      0.016     -2.566      0.010      -0.071      -0.009\n",
      "C(month_travel)[T.9]             -0.0352      0.017     -2.036      0.042      -0.069      -0.001\n",
      "C(month_travel)[T.10]            -0.0331      0.016     -2.080      0.038      -0.064      -0.002\n",
      "C(month_travel)[T.11]            -0.0207      0.016     -1.326      0.185      -0.051       0.010\n",
      "C(month_travel)[T.12]             0.0317      0.015      2.082      0.037       0.002       0.062\n",
      "C(us_state_enc)[T.2]             -0.1933      0.213     -0.909      0.364      -0.610       0.224\n",
      "C(us_state_enc)[T.3]              0.0790      0.043      1.845      0.065      -0.005       0.163\n",
      "C(us_state_enc)[T.4]              0.0022      0.042      0.053      0.958      -0.080       0.085\n",
      "C(us_state_enc)[T.5]             -0.1430      0.053     -2.714      0.007      -0.246      -0.040\n",
      "C(us_state_enc)[T.6]             -0.1128      0.054     -2.082      0.037      -0.219      -0.007\n",
      "C(us_state_enc)[T.7]             -0.1675      0.058     -2.873      0.004      -0.282      -0.053\n",
      "C(us_state_enc)[T.8]             -0.0038      0.052     -0.073      0.941      -0.106       0.098\n",
      "C(us_state_enc)[T.9]              0.0229      0.011      2.026      0.043       0.001       0.045\n",
      "C(us_state_enc)[T.10]            -0.0239      0.022     -1.098      0.272      -0.067       0.019\n",
      "C(us_state_enc)[T.11]             0.0373      0.148      0.252      0.801      -0.253       0.327\n",
      "C(us_state_enc)[T.12]             0.0807      0.073      1.101      0.271      -0.063       0.224\n",
      "C(us_state_enc)[T.13]            -0.1336      0.057     -2.325      0.020      -0.246      -0.021\n",
      "C(us_state_enc)[T.14]             0.0066      0.040      0.165      0.869      -0.071       0.085\n",
      "C(us_state_enc)[T.15]             0.0093      0.042      0.223      0.823      -0.072       0.091\n",
      "C(us_state_enc)[T.16]            -0.0823      0.044     -1.856      0.063      -0.169       0.005\n",
      "C(us_state_enc)[T.17]             0.0277      0.044      0.627      0.531      -0.059       0.114\n",
      "C(us_state_enc)[T.18]            -0.0920      0.042     -2.168      0.030      -0.175      -0.009\n",
      "C(us_state_enc)[T.20]             0.1124      0.046      2.422      0.015       0.021       0.203\n",
      "C(us_state_enc)[T.21]            -0.0750      0.034     -2.224      0.026      -0.141      -0.009\n",
      "C(us_state_enc)[T.22]            -0.1720      0.069     -2.478      0.013      -0.308      -0.036\n",
      "C(us_state_enc)[T.23]             0.0069      0.041      0.169      0.866      -0.073       0.087\n",
      "C(us_state_enc)[T.24]             0.0174      0.040      0.435      0.663      -0.061       0.095\n",
      "C(us_state_enc)[T.25]             0.0492      0.039      1.265      0.206      -0.027       0.125\n",
      "C(us_state_enc)[T.26]            -0.0410      0.034     -1.220      0.222      -0.107       0.025\n",
      "C(us_state_enc)[T.27]             0.0477      0.077      0.615      0.538      -0.104       0.199\n",
      "C(us_state_enc)[T.28]            -0.0831      0.046     -1.793      0.073      -0.174       0.008\n",
      "C(us_state_enc)[T.29]            -0.1160      0.065     -1.791      0.073      -0.243       0.011\n",
      "C(us_state_enc)[T.30]             0.0370      0.043      0.859      0.390      -0.047       0.121\n",
      "C(us_state_enc)[T.31]            -0.1183      0.051     -2.341      0.019      -0.217      -0.019\n",
      "C(us_state_enc)[T.32]             0.0532      0.083      0.637      0.524      -0.110       0.217\n",
      "C(us_state_enc)[T.33]             0.0481      0.015      3.184      0.001       0.018       0.078\n",
      "C(us_state_enc)[T.34]            -0.0275      0.032     -0.865      0.387      -0.090       0.035\n",
      "C(us_state_enc)[T.35]            -0.0107      0.088     -0.122      0.903      -0.182       0.161\n",
      "C(us_state_enc)[T.36]             0.0020      0.038      0.053      0.958      -0.073       0.077\n",
      "C(us_state_enc)[T.37]            -0.0415      0.039     -1.053      0.292      -0.119       0.036\n",
      "C(us_state_enc)[T.38]             0.0915      0.067      1.370      0.171      -0.039       0.223\n",
      "C(us_state_enc)[T.39]             0.0107      0.033      0.321      0.748      -0.055       0.076\n",
      "C(us_state_enc)[T.40]             0.0069      0.059      0.116      0.907      -0.109       0.122\n",
      "C(us_state_enc)[T.41]            -0.0409      0.040     -1.010      0.312      -0.120       0.038\n",
      "C(us_state_enc)[T.42]            -0.0299      0.067     -0.446      0.656      -0.161       0.102\n",
      "C(us_state_enc)[T.43]            -0.0247      0.031     -0.792      0.428      -0.086       0.036\n",
      "C(us_state_enc)[T.44]            -0.0639      0.025     -2.593      0.010      -0.112      -0.016\n",
      "C(us_state_enc)[T.46]             0.0441      0.057      0.780      0.435      -0.067       0.155\n",
      "C(us_state_enc)[T.47]             0.1041      0.066      1.585      0.113      -0.025       0.233\n",
      "C(us_state_enc)[T.48]            -0.0452      0.036     -1.268      0.205      -0.115       0.025\n",
      "C(us_state_enc)[T.49]            -0.0612      0.059     -1.032      0.302      -0.177       0.055\n",
      "C(us_state_enc)[T.51]             0.1344      0.065      2.080      0.037       0.008       0.261\n",
      "C(us_state_enc)[T.52]             0.0789      0.032      2.504      0.012       0.017       0.141\n",
      "C(us_state_enc)[T.53]            -0.2224      0.095     -2.336      0.019      -0.409      -0.036\n",
      "immigrant_population          -2.067e-05      6e-06     -3.445      0.001   -3.24e-05   -8.91e-06\n",
      "import_from_slu               -5.015e-09   7.04e-09     -0.712      0.476   -1.88e-08    8.78e-09\n",
      "age                               0.0025      0.000     10.573      0.000       0.002       0.003\n",
      "distance_miles                 1.771e-05   2.77e-05      0.640      0.522   -3.65e-05     7.2e-05\n",
      "state_percapita_income         1.382e-05      3e-06      4.603      0.000    7.93e-06    1.97e-05\n",
      "state_unemployment                0.0433      0.018      2.431      0.015       0.008       0.078\n",
      "=================================================================================================\n",
      "\n",
      "Incident Rate Ratios (IRR):\n",
      "                                 IRR  Lower CI  Upper CI       P-value\n",
      "Intercept                   1.576762  0.983640  2.527530  5.856442e-02\n",
      "C(sex_enc)[T.0]             0.891859  0.568653  1.398767  6.181819e-01\n",
      "C(sex_enc)[T.1]             0.901479  0.574759  1.413920  6.515138e-01\n",
      "C(marital_status_enc)[T.0]  1.061865  0.572580  1.969255  8.489283e-01\n",
      "C(marital_status_enc)[T.1]  1.037510  0.558719  1.926598  9.071696e-01\n",
      "...                              ...       ...       ...           ...\n",
      "import_from_slu             1.000000  1.000000  1.000000  4.763273e-01\n",
      "age                         1.002547  1.002075  1.003020  3.983495e-26\n",
      "distance_miles              1.000018  0.999963  1.000072  5.222801e-01\n",
      "state_percapita_income      1.000014  1.000008  1.000020  4.156927e-06\n",
      "state_unemployment          1.044214  1.008421  1.081277  1.504971e-02\n",
      "\n",
      "[81 rows x 4 columns]\n",
      "Columns in df_clean_nb: ['los_capped', 'immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_percapita_income', 'state_unemployment', 'sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc', 'predicted', 'residuals']\n",
      "Checking if 'us_state_enc' is in df_clean_nb.columns: True\n",
      "X dtypes after converting to float:\n",
      "const                      float64\n",
      "immigrant_population       float64\n",
      "import_from_slu            float64\n",
      "age                        float64\n",
      "distance_miles             float64\n",
      "state_unemployment         float64\n",
      "sex_enc_1                  float64\n",
      "marital_status_enc_1       float64\n",
      "marital_status_enc_2       float64\n",
      "employment_status_enc_0    float64\n",
      "employment_status_enc_1    float64\n",
      "employment_status_enc_2    float64\n",
      "purpose_simple_2.0         float64\n",
      "purpose_simple_3.0         float64\n",
      "purpose_simple_4.0         float64\n",
      "purpose_simple_5.0         float64\n",
      "accomd_type_enc_1          float64\n",
      "accomd_type_enc_2          float64\n",
      "month_travel_2             float64\n",
      "month_travel_3             float64\n",
      "month_travel_4             float64\n",
      "month_travel_5             float64\n",
      "month_travel_6             float64\n",
      "month_travel_7             float64\n",
      "month_travel_8             float64\n",
      "month_travel_9             float64\n",
      "month_travel_10            float64\n",
      "month_travel_11            float64\n",
      "month_travel_12            float64\n",
      "dtype: object\n",
      "Length of df_clean_model: 132622\n",
      "Length of y: 132622\n",
      "Number of rows in X: 132622\n",
      "Length of groups: 132622\n",
      "\n",
      "Approximated Multilevel Model Results:\n",
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:               MixedLM    Dependent Variable:    los_capped  \n",
      "No. Observations:    132622     Method:                REML        \n",
      "No. Groups:          50         Scale:                 2.3970      \n",
      "Min. group size:     21         Log-Likelihood:        -246343.9716\n",
      "Max. group size:     15890      Converged:             Yes         \n",
      "Mean group size:     2652.4                                        \n",
      "-------------------------------------------------------------------\n",
      "                        Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "const                    3.715    0.262  14.181 0.000  3.202  4.228\n",
      "immigrant_population    -0.000    0.000  -1.076 0.282 -0.000  0.000\n",
      "import_from_slu         -0.000    0.000  -1.484 0.138 -0.000  0.000\n",
      "age                      0.015    0.000  43.099 0.000  0.014  0.016\n",
      "distance_miles           0.000    0.000   3.359 0.001  0.000  0.000\n",
      "state_unemployment      -0.087    0.054  -1.610 0.107 -0.192  0.019\n",
      "sex_enc_1                0.058    0.009   6.736 0.000  0.041  0.075\n",
      "marital_status_enc_1    -0.138    0.030  -4.536 0.000 -0.197 -0.078\n",
      "marital_status_enc_2    -0.245    0.011 -23.224 0.000 -0.266 -0.224\n",
      "employment_status_enc_0 -0.008    0.080  -0.105 0.916 -0.165  0.149\n",
      "employment_status_enc_1  0.079    0.094   0.840 0.401 -0.106  0.264\n",
      "employment_status_enc_2 -0.050    0.104  -0.483 0.629 -0.255  0.154\n",
      "purpose_simple_2.0       2.215    0.052  42.962 0.000  2.114  2.316\n",
      "purpose_simple_3.0       2.059    0.634   3.247 0.001  0.816  3.302\n",
      "purpose_simple_4.0       1.091    0.069  15.857 0.000  0.956  1.226\n",
      "purpose_simple_5.0       1.422    0.050  28.294 0.000  1.324  1.521\n",
      "accomd_type_enc_1        0.234    0.023  10.053 0.000  0.188  0.279\n",
      "accomd_type_enc_2        0.536    0.013  40.363 0.000  0.510  0.562\n",
      "month_travel_2          -0.077    0.022  -3.594 0.000 -0.120 -0.035\n",
      "month_travel_3          -0.016    0.021  -0.749 0.454 -0.057  0.026\n",
      "month_travel_4          -0.128    0.022  -5.804 0.000 -0.171 -0.085\n",
      "month_travel_5          -0.122    0.021  -5.726 0.000 -0.163 -0.080\n",
      "month_travel_6          -0.065    0.021  -3.089 0.002 -0.106 -0.024\n",
      "month_travel_7           0.115    0.021   5.458 0.000  0.074  0.156\n",
      "month_travel_8          -0.238    0.022 -10.651 0.000 -0.281 -0.194\n",
      "month_travel_9          -0.208    0.025  -8.426 0.000 -0.257 -0.160\n",
      "month_travel_10         -0.193    0.023  -8.471 0.000 -0.237 -0.148\n",
      "month_travel_11         -0.126    0.022  -5.663 0.000 -0.170 -0.083\n",
      "month_travel_12          0.169    0.022   7.724 0.000  0.126  0.211\n",
      "Group Var                0.088    0.013                            \n",
      "===================================================================\n",
      "\n",
      "\n",
      "Incident Rate Ratios (IRR) Mixed Model:\n",
      "                               IRR   Lower CI   Upper CI        P-value\n",
      "const                    41.058965  24.570657  68.611867   1.202544e-45\n",
      "immigrant_population      0.999970   0.999915   1.000025   2.819114e-01\n",
      "import_from_slu           1.000000   1.000000   1.000000   1.377563e-01\n",
      "age                       1.014985   1.014299   1.015672   0.000000e+00\n",
      "distance_miles            1.000192   1.000080   1.000304   7.825264e-04\n",
      "state_unemployment        0.917033   0.825255   1.019017   1.074368e-01\n",
      "sex_enc_1                 1.059878   1.042094   1.077966   1.630929e-11\n",
      "marital_status_enc_1      0.871333   0.820986   0.924767   5.744124e-06\n",
      "marital_status_enc_2      0.782796   0.766784   0.799142  2.622174e-119\n",
      "employment_status_enc_0   0.991608   0.847495   1.160226   9.162320e-01\n",
      "employment_status_enc_1   1.082552   0.899734   1.302518   4.006475e-01\n",
      "employment_status_enc_2   0.950857   0.774889   1.166785   6.293628e-01\n",
      "purpose_simple_2.0        9.164450   8.283503  10.139084   0.000000e+00\n",
      "purpose_simple_3.0        7.840875   2.262024  27.178899   1.166489e-03\n",
      "purpose_simple_4.0        2.978174   2.602368   3.408251   1.257960e-56\n",
      "purpose_simple_5.0        4.147085   3.757947   4.576519  4.128606e-176\n",
      "accomd_type_enc_1         1.263327   1.207049   1.322229   8.869406e-24\n",
      "accomd_type_enc_2         1.709833   1.665872   1.754954   0.000000e+00\n",
      "month_travel_2            0.925442   0.887153   0.965384   3.255873e-04\n",
      "month_travel_3            0.984278   0.944295   1.025953   4.538615e-01\n",
      "month_travel_4            0.879970   0.842783   0.918798   6.469937e-09\n",
      "month_travel_5            0.885510   0.849411   0.923143   1.028961e-08\n",
      "month_travel_6            0.937058   0.899196   0.976513   2.005605e-03\n",
      "month_travel_7            1.122008   1.076567   1.169366   4.825130e-08\n",
      "month_travel_8            0.788470   0.754729   0.823718   1.730323e-26\n",
      "month_travel_9            0.812059   0.773670   0.852353   3.591974e-17\n",
      "month_travel_10           0.824785   0.788834   0.862376   2.423630e-17\n",
      "month_travel_11           0.881447   0.843778   0.920798   1.488635e-08\n",
      "month_travel_12           1.183655   1.134079   1.235399   1.131489e-14\n",
      "Group Var                 1.037402   1.020437   1.054649   1.272837e-05\n",
      "VIF for continuous and dummy variables:\n",
      "                   Variable         VIF\n",
      "0      immigrant_population    1.728549\n",
      "1           import_from_slu    1.466896\n",
      "2                       age   13.999374\n",
      "3            distance_miles   25.555194\n",
      "4        state_unemployment   42.588104\n",
      "5                 sex_enc_1    1.847416\n",
      "6      marital_status_enc_1    1.038961\n",
      "7      marital_status_enc_2    1.672845\n",
      "8   employment_status_enc_0  134.579646\n",
      "9   employment_status_enc_1    1.971099\n",
      "10  employment_status_enc_2    1.547103\n",
      "11       purpose_simple_2.0   18.424592\n",
      "12       purpose_simple_3.0    1.005198\n",
      "13       purpose_simple_4.0    1.849887\n",
      "14       purpose_simple_5.0   85.169897\n",
      "15        accomd_type_enc_1    1.045482\n",
      "16        accomd_type_enc_2    1.198525\n",
      "17           month_travel_2    2.224775\n",
      "18           month_travel_3    2.340820\n",
      "19           month_travel_4    2.114815\n",
      "20           month_travel_5    2.351721\n",
      "21           month_travel_6    2.444733\n",
      "22           month_travel_7    2.423702\n",
      "23           month_travel_8    2.087329\n",
      "24           month_travel_9    1.736397\n",
      "25          month_travel_10    2.005850\n",
      "26          month_travel_11    2.075310\n",
      "27          month_travel_12    2.170521\n",
      "\n",
      "Approximated Multilevel Model Results:\n",
      "               Mixed Linear Model Regression Results\n",
      "===================================================================\n",
      "Model:               MixedLM    Dependent Variable:    los_capped  \n",
      "No. Observations:    132622     Method:                REML        \n",
      "No. Groups:          50         Scale:                 2.3969      \n",
      "Min. group size:     21         Log-Likelihood:        -246338.7056\n",
      "Max. group size:     15890      Converged:             Yes         \n",
      "Mean group size:     2652.4                                        \n",
      "-------------------------------------------------------------------\n",
      "                        Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------\n",
      "const                    3.910    0.110  35.456 0.000  3.694  4.126\n",
      "immigrant_population    -0.000    0.000  -1.556 0.120 -0.000  0.000\n",
      "import_from_slu         -0.000    0.000  -1.507 0.132 -0.000  0.000\n",
      "age                      0.015    0.000  43.100 0.000  0.014  0.016\n",
      "sex_enc_1                0.058    0.009   6.733 0.000  0.041  0.075\n",
      "marital_status_enc_1    -0.138    0.030  -4.539 0.000 -0.197 -0.078\n",
      "marital_status_enc_2    -0.245    0.011 -23.223 0.000 -0.266 -0.224\n",
      "employment_status_enc_0 -0.008    0.080  -0.104 0.917 -0.165  0.149\n",
      "employment_status_enc_1  0.079    0.094   0.840 0.401 -0.106  0.264\n",
      "employment_status_enc_2 -0.050    0.104  -0.484 0.629 -0.255  0.154\n",
      "purpose_simple_2.0       2.215    0.052  42.963 0.000  2.114  2.316\n",
      "purpose_simple_3.0       2.060    0.634   3.247 0.001  0.816  3.303\n",
      "purpose_simple_4.0       1.093    0.069  15.877 0.000  0.958  1.228\n",
      "purpose_simple_5.0       1.422    0.050  28.295 0.000  1.324  1.521\n",
      "accomd_type_enc_1        0.234    0.023  10.064 0.000  0.188  0.280\n",
      "accomd_type_enc_2        0.537    0.013  40.377 0.000  0.511  0.563\n",
      "month_travel_2          -0.078    0.022  -3.611 0.000 -0.120 -0.036\n",
      "month_travel_3          -0.016    0.021  -0.768 0.443 -0.058  0.025\n",
      "month_travel_4          -0.128    0.022  -5.825 0.000 -0.171 -0.085\n",
      "month_travel_5          -0.122    0.021  -5.744 0.000 -0.164 -0.080\n",
      "month_travel_6          -0.065    0.021  -3.101 0.002 -0.106 -0.024\n",
      "month_travel_7           0.115    0.021   5.445 0.000  0.074  0.156\n",
      "month_travel_8          -0.238    0.022 -10.663 0.000 -0.282 -0.194\n",
      "month_travel_9          -0.208    0.025  -8.438 0.000 -0.257 -0.160\n",
      "month_travel_10         -0.193    0.023  -8.486 0.000 -0.238 -0.148\n",
      "month_travel_11         -0.126    0.022  -5.676 0.000 -0.170 -0.083\n",
      "month_travel_12          0.168    0.022   7.707 0.000  0.125  0.211\n",
      "Group Var                0.115    0.016                            \n",
      "===================================================================\n",
      "\n",
      "\n",
      "Incident Rate Ratios (IRR) Mixed Model:\n",
      "                               IRR   Lower CI   Upper CI        P-value\n",
      "const                    49.882202  40.187037  61.916337  2.322387e-275\n",
      "immigrant_population      0.999951   0.999890   1.000013   1.196718e-01\n",
      "import_from_slu           1.000000   1.000000   1.000000   1.317984e-01\n",
      "age                       1.014986   1.014299   1.015672   0.000000e+00\n",
      "sex_enc_1                 1.059851   1.042067   1.077937   1.664437e-11\n",
      "marital_status_enc_1      0.871238   0.820898   0.924666   5.646966e-06\n",
      "marital_status_enc_2      0.782801   0.766789   0.799148  2.655106e-119\n",
      "employment_status_enc_0   0.991720   0.847592   1.160356   9.173499e-01\n",
      "employment_status_enc_1   1.082518   0.899707   1.302474   4.008323e-01\n",
      "employment_status_enc_2   0.950761   0.774812   1.166666   6.286759e-01\n",
      "purpose_simple_2.0        9.165046   8.284047  10.139738   0.000000e+00\n",
      "purpose_simple_3.0        7.842482   2.262514  27.184150   1.165039e-03\n",
      "purpose_simple_4.0        2.982297   2.605976   3.412961   9.090956e-57\n",
      "purpose_simple_5.0        4.147354   3.758193   4.576812  3.957381e-176\n",
      "accomd_type_enc_1         1.263630   1.207339   1.322545   7.980600e-24\n",
      "accomd_type_enc_2         1.710150   1.666182   1.755279   0.000000e+00\n",
      "month_travel_2            0.925111   0.886836   0.965038   3.053749e-04\n",
      "month_travel_3            0.983886   0.943920   1.025544   4.425988e-01\n",
      "month_travel_4            0.879571   0.842401   0.918381   5.718019e-09\n",
      "month_travel_5            0.885178   0.849093   0.922797   9.270045e-09\n",
      "month_travel_6            0.936834   0.898982   0.976280   1.930221e-03\n",
      "month_travel_7            1.121715   1.076287   1.169060   5.169786e-08\n",
      "month_travel_8            0.788248   0.754517   0.823486   1.509557e-26\n",
      "month_travel_9            0.811810   0.773433   0.852092   3.229203e-17\n",
      "month_travel_10           0.824515   0.788575   0.862092   2.139564e-17\n",
      "month_travel_11           0.881200   0.843542   0.920539   1.382642e-08\n",
      "month_travel_12           1.183224   1.133666   1.234948   1.288835e-14\n",
      "Group Var                 1.049066   1.028169   1.070387   3.071050e-06\n",
      "VIF for continuous and dummy variables with fewer variables:\n",
      "                   Variable         VIF\n",
      "0      immigrant_population    1.548311\n",
      "1           import_from_slu    1.363277\n",
      "2                       age   13.934927\n",
      "3                 sex_enc_1    1.847237\n",
      "4      marital_status_enc_1    1.038953\n",
      "5      marital_status_enc_2    1.668977\n",
      "6   employment_status_enc_0  115.913751\n",
      "7   employment_status_enc_1    1.833159\n",
      "8   employment_status_enc_2    1.472467\n",
      "9        purpose_simple_2.0   17.955925\n",
      "10       purpose_simple_3.0    1.005131\n",
      "11       purpose_simple_4.0    1.829570\n",
      "12       purpose_simple_5.0   83.210989\n",
      "13        accomd_type_enc_1    1.045144\n",
      "14        accomd_type_enc_2    1.197929\n",
      "15           month_travel_2    2.222470\n",
      "16           month_travel_3    2.334542\n",
      "17           month_travel_4    2.111386\n",
      "18           month_travel_5    2.345962\n",
      "19           month_travel_6    2.433135\n",
      "20           month_travel_7    2.414401\n",
      "21           month_travel_8    2.081934\n",
      "22           month_travel_9    1.733800\n",
      "23          month_travel_10    2.002186\n",
      "24          month_travel_11    2.069201\n",
      "25          month_travel_12    2.164537\n",
      "\n",
      "Please select where to save the Word document...\n",
      "Analysis report saved to: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/new vif and simplified.docx\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families.family import NegativeBinomial\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from scipy import stats\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from io import BytesIO\n",
    "import statsmodels.discrete.discrete_model as discrete\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "def select_file(title, file_types, save=False):\n",
    "    \"\"\"Allow user to select a file\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    try:\n",
    "        if save:\n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types,\n",
    "                defaultextension=file_types[0][1]\n",
    "            )\n",
    "        else:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types\n",
    "            )\n",
    "    finally:\n",
    "        root.destroy()\n",
    "    \n",
    "    return file_path if file_path else None\n",
    "\n",
    "# Allow user to select input file\n",
    "print(\"Please select the input Excel file...\")\n",
    "file_path = select_file(\n",
    "    \"Select Excel Data File\", \n",
    "    [(\"Excel files\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "if not file_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Import the data\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"Sheet\")\n",
    "\n",
    "# Setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Encode categorical variables if not already encoded\n",
    "categorical_vars = ['sex', 'marital_status', 'employment_status', 'purpose', 'accomd_type', 'us_state']\n",
    "encoded_vars = {}\n",
    "\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        # Check if variable is already numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df[var]):\n",
    "            new_var = f\"{var}_enc\"\n",
    "            df[new_var] = pd.Categorical(df[var]).codes\n",
    "            encoded_vars[var] = new_var\n",
    "        else:\n",
    "            encoded_vars[var] = var\n",
    "\n",
    "# Set the truncation point for los (assuming truncation at 0)\n",
    "df['los_trunc'] = df['los'].copy()\n",
    "df.loc[df['los_trunc'] <= 0, 'los_trunc'] = np.nan\n",
    "\n",
    "# Check for missing data\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing_data_summary = df.isnull().sum()\n",
    "print(missing_data_summary)\n",
    "\n",
    "print(\"\\nMissing data patterns:\")\n",
    "missing_patterns = df.isnull().sum(axis=1)\n",
    "missing_patterns_counts = missing_patterns.value_counts().sort_index()\n",
    "print(missing_patterns_counts)\n",
    "\n",
    "# Visualize los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['los_trunc'], discrete=True)\n",
    "plt.title('Histogram of Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_hist_img = BytesIO()\n",
    "plt.savefig(los_hist_img, format='png')\n",
    "los_hist_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Summarize los by purpose\n",
    "purpose_stats = None\n",
    "if 'purpose_enc' in df.columns:\n",
    "    print(\"\\nLength of stay by purpose:\")\n",
    "    purpose_stats = df.groupby('purpose_enc')['los_trunc'].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    print(purpose_stats)\n",
    "\n",
    "# Detailed summary of los_trunc\n",
    "print(\"\\nDetailed summary of length of stay:\")\n",
    "los_describe = df['los_trunc'].describe(percentiles=[.25, .5, .75, .90, .95, .99])\n",
    "print(los_describe)\n",
    "\n",
    "# Cleaning process\n",
    "# Step 1: Drop missing datapoints for key variables\n",
    "key_vars = ['los', 'immigrant_population', 'import_from_slu', 'age', \n",
    "            encoded_vars.get('sex', 'sex_enc'), \n",
    "            encoded_vars.get('marital_status', 'marital_status_enc'), \n",
    "            encoded_vars.get('employment_status', 'employment_status_enc'), \n",
    "            'distance_miles', \n",
    "            encoded_vars.get('purpose', 'purpose_enc'), \n",
    "            encoded_vars.get('accomd_type', 'accomd_type_enc'), \n",
    "            'month_travel', 'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Count missing values per row for key variables\n",
    "df['missing'] = df[key_vars].isnull().sum(axis=1)\n",
    "print(\"\\nNumber of missing values per observation:\")\n",
    "missing_values_count = df['missing'].value_counts().sort_index()\n",
    "print(missing_values_count)\n",
    "\n",
    "# Drop observations with missing values in key variables\n",
    "df_clean = df[df['missing'] == 0].drop('missing', axis=1)\n",
    "print(f\"\\nRemaining observations after dropping missing values: {len(df_clean)}\")\n",
    "\n",
    "# Step 2: Drop outliers in length of stay\n",
    "los_p95 = np.percentile(df_clean['los_trunc'].dropna(), 95)\n",
    "df_clean['los_capped'] = df_clean['los_trunc'].copy()\n",
    "df_clean.loc[df_clean['los_capped'] > los_p95, 'los_capped'] = los_p95\n",
    "\n",
    "df_clean = df_clean[df_clean['los_trunc'] <= los_p95]\n",
    "print(f\"After filtering to 95th percentile, remaining observations: {len(df_clean)}\")\n",
    "\n",
    "\n",
    "# Visualize the capped los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['los_capped'], discrete=True)\n",
    "plt.title('Histogram of Capped Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_capped_img = BytesIO()\n",
    "plt.savefig(los_capped_img, format='png')\n",
    "los_capped_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Clean up the purpose of trip column\n",
    "# Create a new simplified purpose variable\n",
    "purpose_mapping = {\n",
    "    1: 1,  # BUSINESS/MEETING -> Business\n",
    "    2: 1,  # CONVENTION -> Business\n",
    "    3: 1,  # CREW -> Business\n",
    "    5: 2,  # EVENT -> Events\n",
    "    6: 2,  # EVENTS -> Events\n",
    "    7: 4,  # HONEYMOON -> Pleasure\n",
    "    8: 5,  # INTRANSIT PASSEN -> Other\n",
    "    9: 5,  # OTHER -> Other\n",
    "    10: 4, # PLEASURE/HOLIDAY -> Pleasure\n",
    "    11: 5, # RESIDENT -> Other\n",
    "    12: 2, # SAINT LUCIA CARN -> Events\n",
    "    13: 2, # SAINT LUCIA JAZZ -> Events\n",
    "    14: 5, # SPORTS -> Other\n",
    "    15: 5, # STUDY -> Other\n",
    "    16: 5, # VISITING FRIENDS -> Other\n",
    "    17: 3, # WEDDING -> Wedding\n",
    "    18: 4, # pLEASURE/HOLIDAY -> Pleasure\n",
    "    4: 5,  # CRICKET -> Other\n",
    "}\n",
    "\n",
    "purpose_labels = {\n",
    "    1: \"Business\",\n",
    "    2: \"Events\",\n",
    "    3: \"Wedding\",\n",
    "    4: \"Pleasure\",\n",
    "    5: \"Other\"\n",
    "}\n",
    "\n",
    "# Add the simplified purpose variable\n",
    "purpose_enc_col = encoded_vars.get('purpose', 'purpose_enc')\n",
    "df_clean['purpose_simple'] = df_clean[purpose_enc_col].map(purpose_mapping)\n",
    "\n",
    "# Check the new variable\n",
    "print(\"\\nPurpose simple distribution:\")\n",
    "purpose_counts = df_clean['purpose_simple'].value_counts().sort_index()\n",
    "purpose_distribution = []\n",
    "for code, count in purpose_counts.items():\n",
    "    purpose_line = f\"{code} ({purpose_labels.get(code, 'Unknown')}): {count}\"\n",
    "    purpose_distribution.append(purpose_line)\n",
    "    print(purpose_line)\n",
    "\n",
    "# Create a Word document for output\n",
    "doc = Document()\n",
    "doc.add_heading('Multilevel Truncated Negative Binomial Regression for Length of Stay Analysis', 0)\n",
    "doc.add_heading('Data Preparation and Cleaning', level=1)\n",
    "\n",
    "# Add missing data information\n",
    "doc.add_paragraph('Missing Data Summary:')\n",
    "missing_table = doc.add_table(rows=len(missing_data_summary)+1, cols=2)\n",
    "missing_table.style = 'Table Grid'\n",
    "missing_table.cell(0, 0).text = 'Variable'\n",
    "missing_table.cell(0, 1).text = 'Missing Count'\n",
    "for i, (var, count) in enumerate(missing_data_summary.items(), 1):\n",
    "    missing_table.cell(i, 0).text = str(var)\n",
    "    missing_table.cell(i, 1).text = str(count)\n",
    "\n",
    "doc.add_paragraph('\\nMissing Data Patterns:')\n",
    "patterns_table = doc.add_table(rows=len(missing_patterns_counts)+1, cols=2)\n",
    "patterns_table.style = 'Table Grid'\n",
    "patterns_table.cell(0, 0).text = 'Number of Missing Variables'\n",
    "patterns_table.cell(0, 1).text = 'Count'\n",
    "for i, (pattern, count) in enumerate(missing_patterns_counts.items(), 1):\n",
    "    patterns_table.cell(i, 0).text = str(pattern)\n",
    "    patterns_table.cell(i, 1).text = str(count)\n",
    "\n",
    "# Add Length of Stay histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_hist_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 1: Histogram of Length of Stay (Before Capping)')\n",
    "\n",
    "# Add Capped LOS histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Capped Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_capped_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 2: Histogram of Length of Stay (After Capping at 95th Percentile)')\n",
    "\n",
    "# Add LOS summary statistics\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Summary Statistics 95% Capped', level=2)\n",
    "los_stats_table = doc.add_table(rows=len(los_describe)+1, cols=2)\n",
    "los_stats_table.style = 'Table Grid'\n",
    "los_stats_table.cell(0, 0).text = 'Statistic'\n",
    "los_stats_table.cell(0, 1).text = 'Value'\n",
    "for i, (stat, value) in enumerate(los_describe.items(), 1):\n",
    "    los_stats_table.cell(i, 0).text = str(stat)\n",
    "    los_stats_table.cell(i, 1).text = f\"{value:.4f}\" if isinstance(value, (int, float)) else str(value)\n",
    "\n",
    "# Add Purpose distribution\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Purpose of Visit Distribution', level=2)\n",
    "purpose_table = doc.add_table(rows=len(purpose_distribution)+1, cols=1)\n",
    "purpose_table.style = 'Table Grid'\n",
    "purpose_table.cell(0, 0).text = 'Purpose Category'\n",
    "for i, purpose_text in enumerate(purpose_distribution, 1):\n",
    "    purpose_table.cell(i, 0).text = purpose_text\n",
    "\n",
    "# Fit simple negative binomial regression with continuous variables correctly specified\n",
    "print(\"\\nFitting simple negative binomial regression model...\")\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Negative Binomial Regression Model', level=1)\n",
    "\n",
    "# Define continuous variables and create proper formula\n",
    "continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', \n",
    "                   'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Make sure all continuous variables are properly formatted as numeric\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        df_clean[var] = pd.to_numeric(df_clean[var], errors='coerce')\n",
    "\n",
    "# Create formula with continuous variables properly treated\n",
    "formula_parts = []\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        formula_parts.append(var)\n",
    "\n",
    "# Add categorical variables with proper C() notation\n",
    "categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', \n",
    "                         'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc']\n",
    "\n",
    "for var in categorical_model_vars:\n",
    "    if var in df_clean.columns:\n",
    "        # Use the encoded variable name or the original if available\n",
    "        var_to_use = var\n",
    "        formula_parts.append(f\"C({var_to_use})\")\n",
    "\n",
    "# Combine into final formula\n",
    "formula = 'los_capped ~ ' + ' + '.join(formula_parts)\n",
    "print(f\"Model formula: {formula}\")\n",
    "\n",
    "# Add formula to document\n",
    "doc.add_paragraph(f\"Model formula: {formula}\")\n",
    "\n",
    "# Drop rows with missing values in formula variables\n",
    "##formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "df_clean_nb = df_clean[formula_vars].dropna()\n",
    "df_clean_nb = df_clean_nb.reset_index(drop=True)\n",
    "print(f\"Number of rows in df_clean_nb after dropping missing values: {len(df_clean_nb)}\")\n",
    "\n",
    "\n",
    "# Fit negative binomial model\n",
    "nb_model = smf.glm(formula=formula, \n",
    "                  data=df_clean_nb, \n",
    "                  family=sm.families.NegativeBinomial(link=sm.families.links.log()))\n",
    "\n",
    "try:\n",
    "    nb_results = nb_model.fit()\n",
    "    print(\"\\nNegative Binomial Regression Results:\")\n",
    "    summary_text = str(nb_results.summary())\n",
    "    print(summary_text)\n",
    "    \n",
    "    # Add model summary to document\n",
    "    #doc.add_paragraph('\\nModel Summary:')\n",
    "    summary_paragraph_neg = doc.add_paragraph()\n",
    "    summary_run_neg = summary_paragraph_neg.add_run(summary_text)\n",
    "    summary_run_neg.font.name = 'Courier New'  # Use monospace font\n",
    "    #for line in summary_text.split('\\n'):\n",
    "        #doc.add_paragraph(line)\n",
    "    \n",
    "    # Convert coefficients to incident rate ratios (IRR)\n",
    "    print(\"\\nIncident Rate Ratios (IRR):\")\n",
    "    irr = np.exp(nb_results.params)\n",
    "    irr_conf = np.exp(nb_results.conf_int())\n",
    "    irr_df = pd.DataFrame({'IRR': irr, 'Lower CI': irr_conf[0], 'Upper CI': irr_conf[1], \n",
    "                          'P-value': nb_results.pvalues})\n",
    "    print(irr_df)\n",
    "    \n",
    "    # Add IRR table to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Incident Rate Ratios (IRR)', level=2)\n",
    "    irr_table = doc.add_table(rows=len(irr_df)+1, cols=5)\n",
    "    irr_table.style = 'Table Grid'\n",
    "    irr_table.cell(0, 0).text = 'Variable'\n",
    "    irr_table.cell(0, 1).text = 'IRR'\n",
    "    irr_table.cell(0, 2).text = 'Lower CI'\n",
    "    irr_table.cell(0, 3).text = 'Upper CI'\n",
    "    irr_table.cell(0, 4).text = 'P-value'\n",
    "    \n",
    "    for i, (var, row) in enumerate(irr_df.iterrows(), 1):\n",
    "        irr_table.cell(i, 0).text = str(var)\n",
    "        irr_table.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "        irr_table.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "        irr_table.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "        irr_table.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "    \n",
    "    \n",
    "    # Predictions and diagnostics\n",
    "    df_clean_nb['predicted'] = nb_results.predict()\n",
    "    df_clean_nb['residuals'] = df_clean_nb['los_capped'] - df_clean_nb['predicted']\n",
    "    \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_clean_nb['predicted'], df_clean_nb['residuals'], alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.tight_layout()\n",
    "    residuals_img = BytesIO()\n",
    "    plt.savefig(residuals_img, format='png')\n",
    "    residuals_img.seek(0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Add residuals plot to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Diagnostics', level=2)\n",
    "    doc.add_picture(residuals_img, width=Inches(6))\n",
    "    doc.add_paragraph('Figure 3: Residuals Plot')\n",
    "    \n",
    "    # Check for heterogeneity across states if us_state is in the data\n",
    "    if 'us_state_enc' in df_clean_nb.columns or 'us_state' in df_clean_nb.columns:\n",
    "        state_var = 'us_state_enc' if 'us_state_enc' in df_clean_nb.columns else 'us_state'\n",
    "        state_means = df_clean_nb.groupby(state_var)['los_capped'].mean().sort_values()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        state_means.plot(kind='bar')\n",
    "        plt.xlabel('State')\n",
    "        plt.ylabel('Average Length of Stay')\n",
    "        plt.title('Mean Length of Stay by State')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        los_by_state_img = BytesIO()\n",
    "        plt.savefig(los_by_state_img, format='png')\n",
    "        los_by_state_img.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Add state analysis to document\n",
    "        doc.add_paragraph('\\n')\n",
    "        doc.add_heading('State Analysis', level=2)\n",
    "        doc.add_picture(los_by_state_img, width=Inches(6))\n",
    "        doc.add_paragraph('Figure 4: Mean Length of Stay by State')\n",
    "    \n",
    "    # Approximated Multilevel Model\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Approximated Multilevel Model', level=1)\n",
    "    doc.add_paragraph('Using MixedLM to approximate a multilevel model with random effects for states.')\n",
    "    \n",
    "    # Debugging: Check df_clean_nb and the condition\n",
    "    print(\"Columns in df_clean_nb:\", df_clean_nb.columns.tolist())\n",
    "    print(\"Checking if 'us_state_enc' is in df_clean_nb.columns:\", 'us_state_enc' in df_clean_nb.columns)\n",
    "\n",
    "    # Update variable lists\n",
    "    continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_unemployment']\n",
    "    categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc','us_state_enc', 'month_travel']\n",
    "\n",
    "    \n",
    "\n",
    "    # Check if us_state variable exists for multilevel modeling\n",
    "    if 'us_state_enc' in df_clean_nb.columns:\n",
    "        # For demonstration, we'll use a linear mixed model as an approximation\n",
    "        # Prepare model variables\n",
    "        \n",
    "        # Ensure no missing values in variables used for mixed effects model\n",
    "        model_vars = ['los_capped'] + continuous_vars + categorical_model_vars \n",
    "        df_clean_model = df_clean_nb[model_vars].dropna()\n",
    "\n",
    "        df_clean_model = df_clean_model.reset_index(drop=True)\n",
    "\n",
    "        df_clean_model_old= df_clean_model.copy()\n",
    "\n",
    "        # Remove rows where sex_enc is -1\n",
    "        df_clean_model = df_clean_model[df_clean_model['sex_enc'] != -1]\n",
    "        # Remove rows where age > 100\n",
    "        df_clean_model = df_clean_model[df_clean_model['age'] <= 100]\n",
    "        # Remove rows where marital_status_enc is -1\n",
    "        df_clean_model = df_clean_model[df_clean_model['marital_status_enc'] != -1]\n",
    "        \n",
    "        y = df_clean_model['los_capped']\n",
    "        \n",
    "        # Create X matrix for fixed effects\n",
    "        X_vars = []\n",
    "        for var in continuous_vars:\n",
    "            if var in df_clean_model.columns:\n",
    "                X_vars.append(var)\n",
    "        \n",
    "        X = df_clean_model[X_vars].copy()\n",
    "        \n",
    "        # Add categorical variables (one-hot encoded)\n",
    "        for var in categorical_model_vars:\n",
    "            if var in df_clean_model.columns and var != 'us_state_enc':  # Exclude the grouping variable\n",
    "                dummies = pd.get_dummies(df_clean_model[var], prefix=var, drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "        \n",
    "        # Add intercept\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        X=X.astype(float)\n",
    "        print(\"X dtypes after converting to float:\")\n",
    "        print(X.dtypes)\n",
    "\n",
    "        #Create new X's which will be simplified i.e. no multicollinearity\n",
    "        X_simplified = X.copy()\n",
    "        # Drop columns 'distance_miles' and 'state_unemployment' from X\n",
    "        X_simplified = X_simplified.drop(columns=['distance_miles', 'state_unemployment'])\n",
    "        \n",
    "        # Define groups for random effects\n",
    "        groups = df_clean_model['us_state_enc']\n",
    "\n",
    "        print(f\"Length of df_clean_model: {len(df_clean_model)}\")\n",
    "        print(f\"Length of y: {len(y)}\")\n",
    "        print(f\"Number of rows in X: {X.shape[0]}\")\n",
    "        print(f\"Length of groups: {len(groups)}\")\n",
    "\n",
    "        if len(y) != X.shape[0] or len(y) != len(groups):\n",
    "            print('Length mismatch between y, X, and groups. Check data preparation.')\n",
    "            print(f\"y length:{len(y)}\")\n",
    "            print(f\"X rows: {X.shape[0]}\")\n",
    "            print(f\"groups length: {len(groups)}\")\n",
    "            # Check for NaN values in X\n",
    "            print(\"NaN counts in X columns:\")\n",
    "            print(X.isnull().sum())\n",
    "            raise ValueError(\"Lengths of y, X, and groups do not match!\")\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        # Fit mixed effects model\n",
    "        mixed_model = MixedLM(y, X, groups)\n",
    "        try:\n",
    "            mixed_results = mixed_model.fit()\n",
    "            mixed_summary = str(mixed_results.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary:')\n",
    "            summary_paragraph = doc.add_paragraph()\n",
    "            summary_run = summary_paragraph.add_run(mixed_summary)\n",
    "            summary_run.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var = mixed_results.cov_re.iloc[0, 0]\n",
    "            residual_var = mixed_results.scale\n",
    "            icc = state_var / (state_var + residual_var)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model:\")\n",
    "            irr_mixed = np.exp(mixed_results.params)\n",
    "            irr_conf_mixed = np.exp(mixed_results.conf_int())\n",
    "            irr_df_mixed = pd.DataFrame({'IRR': irr_mixed, 'Lower CI': irr_conf_mixed[0], 'Upper CI': irr_conf_mixed[1], \n",
    "                                'P-value': mixed_results.pvalues})\n",
    "            print(irr_df_mixed)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted'] = mixed_results.fittedvalues\n",
    "            df_clean_model['residuals'] = mixed_results.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted'], df_clean_model['residuals'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img, format='png')\n",
    "            residuals_vs_fitted_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 4: Residuals vs Fitted Values')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img = BytesIO()\n",
    "            plt.savefig(qq_plot_img, format='png')\n",
    "            qq_plot_img.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 5: Q-Q Plot of Residuals')\n",
    "\n",
    "            # Fit a simple linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat = -2 * (ols_results.llf - mixed_results.llf)\n",
    "            p_value = stats.chi2.sf(lr_stat, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects: Statistic = {lr_stat:.2f}, P-value = {p_value:.4f}')\n",
    "\n",
    "\n",
    "            # Pseudo-R (McFadden's R approximation)\n",
    "            null_model = smf.mixedlm(\"los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results = null_model.fit()\n",
    "            pseudo_r2 = 1 - (mixed_results.llf / null_results.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R (McFadden): {pseudo_r2:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Check VIF for continuous variables\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            X_continuous = X[[col for col in X.columns if col != 'const']]  # Exclude intercept\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"Variable\"] = X_continuous.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(X_continuous.values, i) for i in range(X_continuous.shape[1])]\n",
    "            print(\"VIF for continuous and dummy variables:\")\n",
    "            print(vif_data)\n",
    "            doc.add_paragraph('\\nVariance Inflation Factor (VIF) for Continuous and Categorical Variables:')\n",
    "            vif_table = doc.add_table(rows=len(vif_data)+1, cols=2)\n",
    "            vif_table.style = 'Table Grid'\n",
    "            vif_table.cell(0, 0).text = 'Variable'\n",
    "            vif_table.cell(0, 1).text = 'VIF'\n",
    "            for i, (var, vif) in enumerate(zip(vif_data[\"Variable\"], vif_data[\"VIF\"]), 1):\n",
    "                vif_table.cell(i, 0).text = str(var)\n",
    "                vif_table.cell(i, 1).text = f\"{vif:.4f}\"\n",
    "            doc.add_paragraph('VIF values above 10 indicate potential multicollinearity issues.')\n",
    "        except ValueError as ve:\n",
    "            error_msg = f\"ValueError in mixed model fitting: {str(ve)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        except RuntimeError as re:\n",
    "            error_msg = f\"RuntimeError in mixed model fitting: {str(re)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")    \n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        \n",
    "        #New mixed effects model starts here this one is a simpler version\n",
    "        # Fit a simpler mixed model with fewer variables\n",
    "\n",
    "        # Fit mixed effects model with fewer variables\n",
    "        mixed_model_simple = MixedLM(y, X_simplified, groups)\n",
    "        try:\n",
    "            mixed_results_simple = mixed_model_simple.fit()\n",
    "            mixed_summary_simple = str(mixed_results_simple.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary_simple)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary with fewer variables:')\n",
    "            summary_paragraph_simple = doc.add_paragraph()\n",
    "            summary_run_simple = summary_paragraph_simple.add_run(mixed_summary_simple)\n",
    "            summary_run_simple.font.name = 'Courier New'  # Use monospace font\n",
    "            #summary_run.font.size = Pt(10)  # Optional: Adjust font size\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components with fewer variables:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results_simple.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results_simple.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var_simple = mixed_results_simple.cov_re.iloc[0, 0]\n",
    "            residual_var_simple = mixed_results_simple.scale\n",
    "            icc_simple = state_var_simple / (state_var_simple + residual_var_simple)\n",
    "\n",
    "            # Add model summary to document\n",
    "            #doc.add_paragraph('\\nMixed Summary:')\n",
    "            #for line in mixed_summary.split('\\n'):\n",
    "                #doc.add_paragraph(line)\n",
    "            \n",
    "            # Convert coefficients to incident rate ratios (IRR)\n",
    "            print(\"\\nIncident Rate Ratios (IRR) Mixed Model:\")\n",
    "            irr_mixed_simple = np.exp(mixed_results_simple.params)\n",
    "            irr_conf_mixed_simple = np.exp(mixed_results_simple.conf_int())\n",
    "            irr_df_mixed_simple = pd.DataFrame({'IRR': irr_mixed_simple, 'Lower CI': irr_conf_mixed_simple[0], 'Upper CI': irr_conf_mixed_simple[1], \n",
    "                                'P-value': mixed_results_simple.pvalues})\n",
    "            print(irr_df_mixed_simple)\n",
    "            \n",
    "            # Add IRR table to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Incident Rate Ratios (IRR) Mixed Model', level=2)\n",
    "            irr_table_mixed = doc.add_table(rows=len(irr_df_mixed_simple)+1, cols=5)\n",
    "            irr_table_mixed.style = 'Table Grid'\n",
    "            irr_table_mixed.cell(0, 0).text = 'Variable'\n",
    "            irr_table_mixed.cell(0, 1).text = 'IRR'\n",
    "            irr_table_mixed.cell(0, 2).text = 'Lower CI'\n",
    "            irr_table_mixed.cell(0, 3).text = 'Upper CI'\n",
    "            irr_table_mixed.cell(0, 4).text = 'P-value'\n",
    "            \n",
    "            for i, (var, row) in enumerate(irr_df_mixed_simple.iterrows(), 1):\n",
    "                irr_table_mixed.cell(i, 0).text = str(var)\n",
    "                irr_table_mixed.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "                irr_table_mixed.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            # After fitting the mixed model\n",
    "            # Compute residuals and fitted values\n",
    "            df_clean_model['fitted_simple'] = mixed_results_simple.fittedvalues\n",
    "            df_clean_model['residuals_simple'] = mixed_results_simple.resid\n",
    "\n",
    "            # Plot residuals vs fitted values\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(df_clean_model['fitted_simple'], df_clean_model['residuals_simple'], alpha=0.5)\n",
    "            plt.axhline(y=0, color='r', linestyle='-')\n",
    "            plt.xlabel('Fitted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals vs Fitted Values')\n",
    "            plt.tight_layout()\n",
    "            residuals_vs_fitted_img_simple = BytesIO()\n",
    "            plt.savefig(residuals_vs_fitted_img_simple, format='png')\n",
    "            residuals_vs_fitted_img_simple.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_paragraph('\\n')\n",
    "            doc.add_heading('Post-Estimation Diagnostics', level=2)\n",
    "            doc.add_picture(residuals_vs_fitted_img_simple, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 5: Residuals vs Fitted Values for Simpler Model')\n",
    "\n",
    "            # Q-Q plot for normality\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            stats.probplot(df_clean_model['residuals_simple'], dist=\"norm\", plot=plt)\n",
    "            plt.title('Q-Q Plot of Residuals Simpler Model')\n",
    "            plt.tight_layout()\n",
    "            qq_plot_img_simple = BytesIO()\n",
    "            plt.savefig(qq_plot_img_simple, format='png')\n",
    "            qq_plot_img_simple.seek(0)\n",
    "            plt.close()\n",
    "\n",
    "            # Add to document\n",
    "            doc.add_picture(qq_plot_img_simple, width=Inches(6))\n",
    "            doc.add_paragraph('Figure 6: Q-Q Plot of Residuals with fewer variables')\n",
    "\n",
    "            # Fit a simple linear model (no random effects)\n",
    "            ols_model = smf.ols(formula, df_clean_nb)\n",
    "            ols_results = ols_model.fit()\n",
    "\n",
    "            # Compute the likelihood ratio test\n",
    "            lr_stat_simple = -2 * (ols_results.llf - mixed_results_simple.llf)\n",
    "            p_value_simple = stats.chi2.sf(lr_stat_simple, df=1)  # df=1 for one random effect\n",
    "            doc.add_paragraph(f'\\nLikelihood Ratio Test for Random Effects with Simple Model: Statistic = {lr_stat:.2f}, P-value = {p_value:.4f}')\n",
    "\n",
    "\n",
    "            # Pseudo-R (McFadden's R approximation)\n",
    "            null_model_simple = smf.mixedlm(\"los_capped ~ 1\", df_clean_model, groups=df_clean_model['us_state_enc'])\n",
    "            null_results_simple = null_model_simple.fit()\n",
    "            pseudo_r2_simple = 1 - (mixed_results_simple.llf / null_results_simple.llf)\n",
    "            doc.add_paragraph(f'\\nPseudo-R (McFadden) fewer variables: {pseudo_r2_simple:.4f}')\n",
    "\n",
    "            \n",
    "\n",
    "            # Check VIF for continuous variables\n",
    "            from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "            X_continuous_simple = X_simplified[[col for col in X_simplified.columns if col != 'const']]  # Exclude intercept\n",
    "            vif_data_simple = pd.DataFrame()\n",
    "            vif_data_simple[\"Variable\"] = X_continuous_simple.columns\n",
    "            vif_data_simple[\"VIF\"] = [variance_inflation_factor(X_continuous_simple.values, i) for i in range(X_continuous_simple.shape[1])]\n",
    "            print(\"VIF for continuous and dummy variables with fewer variables:\")\n",
    "            print(vif_data_simple)\n",
    "            doc.add_paragraph('\\nVariance Inflation Factor (VIF) for Continuous and Categorical Variables with fewer variables:')\n",
    "            vif_table = doc.add_table(rows=len(vif_data_simple)+1, cols=2)\n",
    "            vif_table.style = 'Table Grid'\n",
    "            vif_table.cell(0, 0).text = 'Variable'\n",
    "            vif_table.cell(0, 1).text = 'VIF'\n",
    "            for i, (var, vif) in enumerate(zip(vif_data_simple[\"Variable\"], vif_data_simple[\"VIF\"]), 1):\n",
    "                vif_table.cell(i, 0).text = str(var)\n",
    "                vif_table.cell(i, 1).text = f\"{vif:.4f}\"\n",
    "            doc.add_paragraph('VIF values above 10 indicate potential multicollinearity issues.')\n",
    "        except ValueError as ve:\n",
    "            error_msg = f\"ValueError in mixed model fitting: {str(ve)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        except RuntimeError as re:\n",
    "            error_msg = f\"RuntimeError in mixed model fitting: {str(re)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")    \n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "        \n",
    "        #second mixed effects model ends here\n",
    "    else:\n",
    "        no_state_msg = \"State variable not found for multilevel modeling.\"\n",
    "        print(no_state_msg)\n",
    "        doc.add_paragraph(no_state_msg)\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"\\nError in model fitting: {str(e)}\"\n",
    "    print(error_msg)\n",
    "    doc.add_paragraph(error_msg)\n",
    "    doc.add_paragraph(\"You may need to check your data or consider using a different modeling approach.\")\n",
    "\n",
    "# Save the Word document\n",
    "print(\"\\nPlease select where to save the Word document...\")\n",
    "doc_path = select_file(\n",
    "    \"Save Analysis Report As\", \n",
    "    [(\"Word Document\", \"*.docx\"), (\"All files\", \"*.*\")],\n",
    "    save=True\n",
    ")\n",
    "\n",
    "if doc_path:\n",
    "    if not doc_path.endswith('.docx'):\n",
    "        doc_path += '.docx'\n",
    "    doc.save(doc_path)\n",
    "    print(f\"Analysis report saved to: {doc_path}\")\n",
    "else:\n",
    "    print(\"Document not saved as no location was selected.\")\n",
    "\n",
    "print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlslu2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
