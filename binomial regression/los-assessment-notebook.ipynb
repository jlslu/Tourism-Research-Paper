{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the input Excel file...\n",
      "Loading data from: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/stata raw data.xlsx\n",
      "\n",
      "Missing data summary:\n",
      "los                         75\n",
      "age                          0\n",
      "sex                         26\n",
      "marital_status              12\n",
      "employment_status          425\n",
      "distance_miles               0\n",
      "purpose                    403\n",
      "accomd_type                  0\n",
      "state_percapita_income       0\n",
      "state_unemployment           0\n",
      "travel_date                  0\n",
      "month_travel                 0\n",
      "import_from_slu              0\n",
      "immigrant_population         0\n",
      "us_state                     0\n",
      "sex_enc                      0\n",
      "marital_status_enc           0\n",
      "employment_status_enc        0\n",
      "purpose_enc                  0\n",
      "accomd_type_enc              0\n",
      "us_state_enc                 0\n",
      "los_trunc                 2178\n",
      "dtype: int64\n",
      "\n",
      "Missing data patterns:\n",
      "0    142227\n",
      "1      2910\n",
      "2       103\n",
      "3         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of stay by purpose:\n",
      "              count        mean  median  min      max          std\n",
      "purpose_enc                                                       \n",
      "-1              389    7.748072     6.0  2.0    373.0    19.536597\n",
      " 0             2131    6.845612     4.0  1.0    372.0    21.176125\n",
      " 1              425    6.334118     5.0  1.0    368.0    18.004622\n",
      " 2              175    7.000000     4.0  1.0    124.0    13.963005\n",
      " 3              432    4.282407     4.0  1.0     17.0     2.203955\n",
      " 4                2    7.000000     7.0  7.0      7.0     0.000000\n",
      " 5              407    6.154791     5.0  2.0     92.0     6.614890\n",
      " 6            22066    6.658253     6.0  1.0    372.0     6.694363\n",
      " 7             1212   69.916667     7.0  1.0  73109.0  2099.927812\n",
      " 8             1361  119.255694     7.0  1.0  73055.0  2799.175773\n",
      " 9           102372    8.927089     6.0  1.0  64986.0   264.902993\n",
      " 10              28    9.857143     7.0  2.0     29.0     6.948031\n",
      " 11            1399    7.987848     7.0  1.0    159.0     7.711945\n",
      " 12             377    6.785146     5.0  1.0    157.0    10.564593\n",
      " 13             177    5.762712     5.0  1.0     42.0     4.328837\n",
      " 14              42   12.214286     7.0  3.0    166.0    24.656208\n",
      " 15            3439   13.221867     8.0  1.0    393.0    25.614415\n",
      " 16            6623    6.179828     5.0  1.0    375.0    14.807467\n",
      " 17               6    6.333333     6.0  6.0      7.0     0.516398\n",
      "\n",
      "Detailed summary of length of stay:\n",
      "count    143063.000000\n",
      "mean         10.035565\n",
      "std         402.763642\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%           6.000000\n",
      "75%           7.000000\n",
      "90%           8.000000\n",
      "95%          10.000000\n",
      "99%          28.000000\n",
      "max       73109.000000\n",
      "Name: los_trunc, dtype: float64\n",
      "\n",
      "Number of missing values per observation:\n",
      "missing\n",
      "0    145166\n",
      "1        75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Remaining observations after dropping missing values: 145166\n",
      "After filtering to 95th percentile, remaining observations: 136252\n",
      "\n",
      "Purpose simple distribution:\n",
      "1.0 (Business): 980\n",
      "2.0 (Events): 22549\n",
      "3.0 (Wedding): 6\n",
      "4.0 (Pleasure): 1104\n",
      "5.0 (Other): 109257\n",
      "\n",
      "Fitting simple negative binomial regression model...\n",
      "Model formula: los_capped ~ immigrant_population + import_from_slu + age + distance_miles + state_percapita_income + state_unemployment + C(sex_enc) + C(marital_status_enc) + C(employment_status_enc) + C(purpose_simple) + C(accomd_type_enc) + C(month_travel) + C(us_state_enc)\n",
      "Number of rows in df_clean_nb after dropping missing values: 132666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/jlslu2025/lib/python3.13/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Negative Binomial Regression Results:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             los_capped   No. Observations:               132666\n",
      "Model:                            GLM   Df Residuals:                   132590\n",
      "Model Family:        NegativeBinomial   Df Model:                           75\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -3.7630e+05\n",
      "Date:                Fri, 14 Mar 2025   Deviance:                       8931.3\n",
      "Time:                        14:03:34   Pearson chi2:                 8.24e+03\n",
      "No. Iterations:                    65   Pseudo R-squ. (CS):           0.007270\n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.4554      0.241      1.891      0.059      -0.016       0.927\n",
      "C(sex_enc)[T.0]                  -0.1144      0.230     -0.498      0.618      -0.564       0.336\n",
      "C(sex_enc)[T.1]                  -0.1037      0.230     -0.452      0.652      -0.554       0.346\n",
      "C(marital_status_enc)[T.0]        0.0600      0.315      0.190      0.849      -0.558       0.678\n",
      "C(marital_status_enc)[T.1]        0.0368      0.316      0.117      0.907      -0.582       0.656\n",
      "C(marital_status_enc)[T.2]        0.0159      0.315      0.051      0.960      -0.602       0.634\n",
      "C(employment_status_enc)[T.0]    -0.0022      0.056     -0.039      0.969      -0.112       0.107\n",
      "C(employment_status_enc)[T.1]     0.0137      0.066      0.208      0.835      -0.115       0.143\n",
      "C(employment_status_enc)[T.2]    -0.0100      0.073     -0.138      0.890      -0.153       0.133\n",
      "C(purpose_simple)[T.2.0]          0.4182      0.037     11.338      0.000       0.346       0.491\n",
      "C(purpose_simple)[T.3.0]          0.3963      0.441      0.899      0.369      -0.468       1.260\n",
      "C(purpose_simple)[T.4.0]          0.2246      0.049      4.600      0.000       0.129       0.320\n",
      "C(purpose_simple)[T.5.0]          0.2817      0.036      7.821      0.000       0.211       0.352\n",
      "C(accomd_type_enc)[T.1]           0.0413      0.016      2.543      0.011       0.009       0.073\n",
      "C(accomd_type_enc)[T.2]           0.0935      0.009     10.082      0.000       0.075       0.112\n",
      "C(month_travel)[T.2]             -0.0132      0.015     -0.877      0.381      -0.043       0.016\n",
      "C(month_travel)[T.3]             -0.0009      0.015     -0.060      0.952      -0.030       0.028\n",
      "C(month_travel)[T.4]             -0.0203      0.015     -1.317      0.188      -0.050       0.010\n",
      "C(month_travel)[T.5]             -0.0188      0.015     -1.265      0.206      -0.048       0.010\n",
      "C(month_travel)[T.6]             -0.0094      0.015     -0.637      0.524      -0.038       0.019\n",
      "C(month_travel)[T.7]              0.0233      0.015      1.582      0.114      -0.006       0.052\n",
      "C(month_travel)[T.8]             -0.0401      0.016     -2.566      0.010      -0.071      -0.009\n",
      "C(month_travel)[T.9]             -0.0352      0.017     -2.036      0.042      -0.069      -0.001\n",
      "C(month_travel)[T.10]            -0.0331      0.016     -2.080      0.038      -0.064      -0.002\n",
      "C(month_travel)[T.11]            -0.0207      0.016     -1.326      0.185      -0.051       0.010\n",
      "C(month_travel)[T.12]             0.0317      0.015      2.082      0.037       0.002       0.062\n",
      "C(us_state_enc)[T.2]             -0.1933      0.213     -0.909      0.364      -0.610       0.224\n",
      "C(us_state_enc)[T.3]              0.0790      0.043      1.845      0.065      -0.005       0.163\n",
      "C(us_state_enc)[T.4]              0.0022      0.042      0.053      0.958      -0.080       0.085\n",
      "C(us_state_enc)[T.5]             -0.1430      0.053     -2.714      0.007      -0.246      -0.040\n",
      "C(us_state_enc)[T.6]             -0.1128      0.054     -2.082      0.037      -0.219      -0.007\n",
      "C(us_state_enc)[T.7]             -0.1675      0.058     -2.873      0.004      -0.282      -0.053\n",
      "C(us_state_enc)[T.8]             -0.0038      0.052     -0.073      0.941      -0.106       0.098\n",
      "C(us_state_enc)[T.9]              0.0229      0.011      2.026      0.043       0.001       0.045\n",
      "C(us_state_enc)[T.10]            -0.0239      0.022     -1.098      0.272      -0.067       0.019\n",
      "C(us_state_enc)[T.11]             0.0373      0.148      0.252      0.801      -0.253       0.327\n",
      "C(us_state_enc)[T.12]             0.0807      0.073      1.101      0.271      -0.063       0.224\n",
      "C(us_state_enc)[T.13]            -0.1336      0.057     -2.325      0.020      -0.246      -0.021\n",
      "C(us_state_enc)[T.14]             0.0066      0.040      0.165      0.869      -0.071       0.085\n",
      "C(us_state_enc)[T.15]             0.0093      0.042      0.223      0.823      -0.072       0.091\n",
      "C(us_state_enc)[T.16]            -0.0823      0.044     -1.856      0.063      -0.169       0.005\n",
      "C(us_state_enc)[T.17]             0.0277      0.044      0.627      0.531      -0.059       0.114\n",
      "C(us_state_enc)[T.18]            -0.0920      0.042     -2.168      0.030      -0.175      -0.009\n",
      "C(us_state_enc)[T.20]             0.1124      0.046      2.422      0.015       0.021       0.203\n",
      "C(us_state_enc)[T.21]            -0.0750      0.034     -2.224      0.026      -0.141      -0.009\n",
      "C(us_state_enc)[T.22]            -0.1720      0.069     -2.478      0.013      -0.308      -0.036\n",
      "C(us_state_enc)[T.23]             0.0069      0.041      0.169      0.866      -0.073       0.087\n",
      "C(us_state_enc)[T.24]             0.0174      0.040      0.435      0.663      -0.061       0.095\n",
      "C(us_state_enc)[T.25]             0.0492      0.039      1.265      0.206      -0.027       0.125\n",
      "C(us_state_enc)[T.26]            -0.0410      0.034     -1.220      0.222      -0.107       0.025\n",
      "C(us_state_enc)[T.27]             0.0477      0.077      0.615      0.538      -0.104       0.199\n",
      "C(us_state_enc)[T.28]            -0.0831      0.046     -1.793      0.073      -0.174       0.008\n",
      "C(us_state_enc)[T.29]            -0.1160      0.065     -1.791      0.073      -0.243       0.011\n",
      "C(us_state_enc)[T.30]             0.0370      0.043      0.859      0.390      -0.047       0.121\n",
      "C(us_state_enc)[T.31]            -0.1183      0.051     -2.341      0.019      -0.217      -0.019\n",
      "C(us_state_enc)[T.32]             0.0532      0.083      0.637      0.524      -0.110       0.217\n",
      "C(us_state_enc)[T.33]             0.0481      0.015      3.184      0.001       0.018       0.078\n",
      "C(us_state_enc)[T.34]            -0.0275      0.032     -0.865      0.387      -0.090       0.035\n",
      "C(us_state_enc)[T.35]            -0.0107      0.088     -0.122      0.903      -0.182       0.161\n",
      "C(us_state_enc)[T.36]             0.0020      0.038      0.053      0.958      -0.073       0.077\n",
      "C(us_state_enc)[T.37]            -0.0415      0.039     -1.053      0.292      -0.119       0.036\n",
      "C(us_state_enc)[T.38]             0.0915      0.067      1.370      0.171      -0.039       0.223\n",
      "C(us_state_enc)[T.39]             0.0107      0.033      0.321      0.748      -0.055       0.076\n",
      "C(us_state_enc)[T.40]             0.0069      0.059      0.116      0.907      -0.109       0.122\n",
      "C(us_state_enc)[T.41]            -0.0409      0.040     -1.010      0.312      -0.120       0.038\n",
      "C(us_state_enc)[T.42]            -0.0299      0.067     -0.446      0.656      -0.161       0.102\n",
      "C(us_state_enc)[T.43]            -0.0247      0.031     -0.792      0.428      -0.086       0.036\n",
      "C(us_state_enc)[T.44]            -0.0639      0.025     -2.593      0.010      -0.112      -0.016\n",
      "C(us_state_enc)[T.46]             0.0441      0.057      0.780      0.435      -0.067       0.155\n",
      "C(us_state_enc)[T.47]             0.1041      0.066      1.585      0.113      -0.025       0.233\n",
      "C(us_state_enc)[T.48]            -0.0452      0.036     -1.268      0.205      -0.115       0.025\n",
      "C(us_state_enc)[T.49]            -0.0612      0.059     -1.032      0.302      -0.177       0.055\n",
      "C(us_state_enc)[T.51]             0.1344      0.065      2.080      0.037       0.008       0.261\n",
      "C(us_state_enc)[T.52]             0.0789      0.032      2.504      0.012       0.017       0.141\n",
      "C(us_state_enc)[T.53]            -0.2224      0.095     -2.336      0.019      -0.409      -0.036\n",
      "immigrant_population          -2.067e-05      6e-06     -3.445      0.001   -3.24e-05   -8.91e-06\n",
      "import_from_slu               -5.015e-09   7.04e-09     -0.712      0.476   -1.88e-08    8.78e-09\n",
      "age                               0.0025      0.000     10.573      0.000       0.002       0.003\n",
      "distance_miles                 1.771e-05   2.77e-05      0.640      0.522   -3.65e-05     7.2e-05\n",
      "state_percapita_income         1.382e-05      3e-06      4.603      0.000    7.93e-06    1.97e-05\n",
      "state_unemployment                0.0433      0.018      2.431      0.015       0.008       0.078\n",
      "=================================================================================================\n",
      "\n",
      "Incident Rate Ratios (IRR):\n",
      "                                 IRR  Lower CI  Upper CI       P-value\n",
      "Intercept                   1.576762  0.983640  2.527530  5.856442e-02\n",
      "C(sex_enc)[T.0]             0.891859  0.568653  1.398767  6.181819e-01\n",
      "C(sex_enc)[T.1]             0.901479  0.574759  1.413920  6.515138e-01\n",
      "C(marital_status_enc)[T.0]  1.061865  0.572580  1.969255  8.489283e-01\n",
      "C(marital_status_enc)[T.1]  1.037510  0.558719  1.926598  9.071696e-01\n",
      "...                              ...       ...       ...           ...\n",
      "import_from_slu             1.000000  1.000000  1.000000  4.763273e-01\n",
      "age                         1.002547  1.002075  1.003020  3.983495e-26\n",
      "distance_miles              1.000018  0.999963  1.000072  5.222801e-01\n",
      "state_percapita_income      1.000014  1.000008  1.000020  4.156927e-06\n",
      "state_unemployment          1.044214  1.008421  1.081277  1.504971e-02\n",
      "\n",
      "[81 rows x 4 columns]\n",
      "Columns in df_clean_nb: ['los_capped', 'immigrant_population', 'import_from_slu', 'age', 'distance_miles', 'state_percapita_income', 'state_unemployment', 'sex_enc', 'marital_status_enc', 'employment_status_enc', 'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc', 'predicted', 'residuals']\n",
      "Checking if 'us_state_enc' is in df_clean_nb.columns: True\n",
      "Length of df_clean_model: 132666\n",
      "Length of y: 132666\n",
      "Number of rows in X: 132666\n",
      "Length of groups: 132666\n",
      "\n",
      "Error in model fitting: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).\n",
      "\n",
      "Please select where to save the Word document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 14:03:36.909 python[4065:8521578] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis report saved to: /Users/janai/Library/CloudStorage/OneDrive-SharedLibraries-jlconsulting.llc/Projects - Documents/Research/Saint Lucia Tourism Piece/notebook 8th attempt.docx\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families.family import NegativeBinomial\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from scipy import stats\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from io import BytesIO\n",
    "import statsmodels.discrete.discrete_model as discrete\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "def select_file(title, file_types, save=False):\n",
    "    \"\"\"Allow user to select a file\"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.attributes('-topmost', True)\n",
    "    \n",
    "    try:\n",
    "        if save:\n",
    "            file_path = filedialog.asksaveasfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types,\n",
    "                defaultextension=file_types[0][1]\n",
    "            )\n",
    "        else:\n",
    "            file_path = filedialog.askopenfilename(\n",
    "                title=title,\n",
    "                filetypes=file_types\n",
    "            )\n",
    "    finally:\n",
    "        root.destroy()\n",
    "    \n",
    "    return file_path if file_path else None\n",
    "\n",
    "# Allow user to select input file\n",
    "print(\"Please select the input Excel file...\")\n",
    "file_path = select_file(\n",
    "    \"Select Excel Data File\", \n",
    "    [(\"Excel files\", \"*.xlsx *.xls\"), (\"All files\", \"*.*\")]\n",
    ")\n",
    "\n",
    "if not file_path:\n",
    "    print(\"No file selected. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Import the data\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "df = pd.read_excel(file_path, sheet_name=\"Stata\")\n",
    "\n",
    "# Setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Encode categorical variables if not already encoded\n",
    "categorical_vars = ['sex', 'marital_status', 'employment_status', 'purpose', 'accomd_type', 'us_state']\n",
    "encoded_vars = {}\n",
    "\n",
    "for var in categorical_vars:\n",
    "    if var in df.columns:\n",
    "        # Check if variable is already numeric\n",
    "        if not pd.api.types.is_numeric_dtype(df[var]):\n",
    "            new_var = f\"{var}_enc\"\n",
    "            df[new_var] = pd.Categorical(df[var]).codes\n",
    "            encoded_vars[var] = new_var\n",
    "        else:\n",
    "            encoded_vars[var] = var\n",
    "\n",
    "# Set the truncation point for los (assuming truncation at 0)\n",
    "df['los_trunc'] = df['los'].copy()\n",
    "df.loc[df['los_trunc'] <= 0, 'los_trunc'] = np.nan\n",
    "\n",
    "# Check for missing data\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing_data_summary = df.isnull().sum()\n",
    "print(missing_data_summary)\n",
    "\n",
    "print(\"\\nMissing data patterns:\")\n",
    "missing_patterns = df.isnull().sum(axis=1)\n",
    "missing_patterns_counts = missing_patterns.value_counts().sort_index()\n",
    "print(missing_patterns_counts)\n",
    "\n",
    "# Visualize los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['los_trunc'], discrete=True)\n",
    "plt.title('Histogram of Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_hist_img = BytesIO()\n",
    "plt.savefig(los_hist_img, format='png')\n",
    "los_hist_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Summarize los by purpose\n",
    "purpose_stats = None\n",
    "if 'purpose_enc' in df.columns:\n",
    "    print(\"\\nLength of stay by purpose:\")\n",
    "    purpose_stats = df.groupby('purpose_enc')['los_trunc'].agg(['count', 'mean', 'median', 'min', 'max', 'std'])\n",
    "    print(purpose_stats)\n",
    "\n",
    "# Detailed summary of los_trunc\n",
    "print(\"\\nDetailed summary of length of stay:\")\n",
    "los_describe = df['los_trunc'].describe(percentiles=[.25, .5, .75, .90, .95, .99])\n",
    "print(los_describe)\n",
    "\n",
    "# Cleaning process\n",
    "# Step 1: Drop missing datapoints for key variables\n",
    "key_vars = ['los', 'immigrant_population', 'import_from_slu', 'age', \n",
    "            encoded_vars.get('sex', 'sex_enc'), \n",
    "            encoded_vars.get('marital_status', 'marital_status_enc'), \n",
    "            encoded_vars.get('employment_status', 'employment_status_enc'), \n",
    "            'distance_miles', \n",
    "            encoded_vars.get('purpose', 'purpose_enc'), \n",
    "            encoded_vars.get('accomd_type', 'accomd_type_enc'), \n",
    "            'month_travel', 'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Count missing values per row for key variables\n",
    "df['missing'] = df[key_vars].isnull().sum(axis=1)\n",
    "print(\"\\nNumber of missing values per observation:\")\n",
    "missing_values_count = df['missing'].value_counts().sort_index()\n",
    "print(missing_values_count)\n",
    "\n",
    "# Drop observations with missing values in key variables\n",
    "df_clean = df[df['missing'] == 0].drop('missing', axis=1)\n",
    "print(f\"\\nRemaining observations after dropping missing values: {len(df_clean)}\")\n",
    "\n",
    "# Step 2: Drop outliers in length of stay\n",
    "los_p95 = np.percentile(df_clean['los_trunc'].dropna(), 95)\n",
    "df_clean['los_capped'] = df_clean['los_trunc'].copy()\n",
    "df_clean.loc[df_clean['los_capped'] > los_p95, 'los_capped'] = los_p95\n",
    "\n",
    "df_clean = df_clean[df_clean['los_trunc'] <= los_p95]\n",
    "print(f\"After filtering to 95th percentile, remaining observations: {len(df_clean)}\")\n",
    "\n",
    "\n",
    "# Visualize the capped los distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['los_capped'], discrete=True)\n",
    "plt.title('Histogram of Capped Length of Stay')\n",
    "plt.tight_layout()\n",
    "los_capped_img = BytesIO()\n",
    "plt.savefig(los_capped_img, format='png')\n",
    "los_capped_img.seek(0)\n",
    "plt.close()\n",
    "\n",
    "# Step 3: Clean up the purpose of trip column\n",
    "# Create a new simplified purpose variable\n",
    "purpose_mapping = {\n",
    "    1: 1,  # BUSINESS/MEETING -> Business\n",
    "    2: 1,  # CONVENTION -> Business\n",
    "    3: 1,  # CREW -> Business\n",
    "    5: 2,  # EVENT -> Events\n",
    "    6: 2,  # EVENTS -> Events\n",
    "    7: 4,  # HONEYMOON -> Pleasure\n",
    "    8: 5,  # INTRANSIT PASSEN -> Other\n",
    "    9: 5,  # OTHER -> Other\n",
    "    10: 4, # PLEASURE/HOLIDAY -> Pleasure\n",
    "    11: 5, # RESIDENT -> Other\n",
    "    12: 2, # SAINT LUCIA CARN -> Events\n",
    "    13: 2, # SAINT LUCIA JAZZ -> Events\n",
    "    14: 5, # SPORTS -> Other\n",
    "    15: 5, # STUDY -> Other\n",
    "    16: 5, # VISITING FRIENDS -> Other\n",
    "    17: 3, # WEDDING -> Wedding\n",
    "    18: 4, # pLEASURE/HOLIDAY -> Pleasure\n",
    "    4: 5,  # CRICKET -> Other\n",
    "}\n",
    "\n",
    "purpose_labels = {\n",
    "    1: \"Business\",\n",
    "    2: \"Events\",\n",
    "    3: \"Wedding\",\n",
    "    4: \"Pleasure\",\n",
    "    5: \"Other\"\n",
    "}\n",
    "\n",
    "# Add the simplified purpose variable\n",
    "purpose_enc_col = encoded_vars.get('purpose', 'purpose_enc')\n",
    "df_clean['purpose_simple'] = df_clean[purpose_enc_col].map(purpose_mapping)\n",
    "\n",
    "# Check the new variable\n",
    "print(\"\\nPurpose simple distribution:\")\n",
    "purpose_counts = df_clean['purpose_simple'].value_counts().sort_index()\n",
    "purpose_distribution = []\n",
    "for code, count in purpose_counts.items():\n",
    "    purpose_line = f\"{code} ({purpose_labels.get(code, 'Unknown')}): {count}\"\n",
    "    purpose_distribution.append(purpose_line)\n",
    "    print(purpose_line)\n",
    "\n",
    "# Create a Word document for output\n",
    "doc = Document()\n",
    "doc.add_heading('Multilevel Truncated Negative Binomial Regression for Length of Stay Analysis', 0)\n",
    "doc.add_heading('Data Preparation and Cleaning', level=1)\n",
    "\n",
    "# Add missing data information\n",
    "doc.add_paragraph('Missing Data Summary:')\n",
    "missing_table = doc.add_table(rows=len(missing_data_summary)+1, cols=2)\n",
    "missing_table.style = 'Table Grid'\n",
    "missing_table.cell(0, 0).text = 'Variable'\n",
    "missing_table.cell(0, 1).text = 'Missing Count'\n",
    "for i, (var, count) in enumerate(missing_data_summary.items(), 1):\n",
    "    missing_table.cell(i, 0).text = str(var)\n",
    "    missing_table.cell(i, 1).text = str(count)\n",
    "\n",
    "doc.add_paragraph('\\nMissing Data Patterns:')\n",
    "patterns_table = doc.add_table(rows=len(missing_patterns_counts)+1, cols=2)\n",
    "patterns_table.style = 'Table Grid'\n",
    "patterns_table.cell(0, 0).text = 'Number of Missing Variables'\n",
    "patterns_table.cell(0, 1).text = 'Count'\n",
    "for i, (pattern, count) in enumerate(missing_patterns_counts.items(), 1):\n",
    "    patterns_table.cell(i, 0).text = str(pattern)\n",
    "    patterns_table.cell(i, 1).text = str(count)\n",
    "\n",
    "# Add Length of Stay histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_hist_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 1: Histogram of Length of Stay (Before Capping)')\n",
    "\n",
    "# Add Capped LOS histogram\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Capped Length of Stay Distribution', level=2)\n",
    "doc.add_picture(los_capped_img, width=Inches(6))\n",
    "doc.add_paragraph('Figure 2: Histogram of Length of Stay (After Capping at 95th Percentile)')\n",
    "\n",
    "# Add LOS summary statistics\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Length of Stay Summary Statistics', level=2)\n",
    "los_stats_table = doc.add_table(rows=len(los_describe)+1, cols=2)\n",
    "los_stats_table.style = 'Table Grid'\n",
    "los_stats_table.cell(0, 0).text = 'Statistic'\n",
    "los_stats_table.cell(0, 1).text = 'Value'\n",
    "for i, (stat, value) in enumerate(los_describe.items(), 1):\n",
    "    los_stats_table.cell(i, 0).text = str(stat)\n",
    "    los_stats_table.cell(i, 1).text = f\"{value:.4f}\" if isinstance(value, (int, float)) else str(value)\n",
    "\n",
    "# Add Purpose distribution\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Purpose of Visit Distribution', level=2)\n",
    "purpose_table = doc.add_table(rows=len(purpose_distribution)+1, cols=1)\n",
    "purpose_table.style = 'Table Grid'\n",
    "purpose_table.cell(0, 0).text = 'Purpose Category'\n",
    "for i, purpose_text in enumerate(purpose_distribution, 1):\n",
    "    purpose_table.cell(i, 0).text = purpose_text\n",
    "\n",
    "# Fit simple negative binomial regression with continuous variables correctly specified\n",
    "print(\"\\nFitting simple negative binomial regression model...\")\n",
    "doc.add_paragraph('\\n')\n",
    "doc.add_heading('Negative Binomial Regression Model', level=1)\n",
    "\n",
    "# Define continuous variables and create proper formula\n",
    "continuous_vars = ['immigrant_population', 'import_from_slu', 'age', 'distance_miles', \n",
    "                   'state_percapita_income', 'state_unemployment']\n",
    "\n",
    "# Make sure all continuous variables are properly formatted as numeric\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        df_clean[var] = pd.to_numeric(df_clean[var], errors='coerce')\n",
    "\n",
    "# Create formula with continuous variables properly treated\n",
    "formula_parts = []\n",
    "for var in continuous_vars:\n",
    "    if var in df_clean.columns:\n",
    "        formula_parts.append(var)\n",
    "\n",
    "# Add categorical variables with proper C() notation\n",
    "categorical_model_vars = ['sex_enc', 'marital_status_enc', 'employment_status_enc', \n",
    "                         'purpose_simple', 'accomd_type_enc', 'month_travel', 'us_state_enc']\n",
    "\n",
    "for var in categorical_model_vars:\n",
    "    if var in df_clean.columns:\n",
    "        # Use the encoded variable name or the original if available\n",
    "        var_to_use = var\n",
    "        formula_parts.append(f\"C({var_to_use})\")\n",
    "\n",
    "# Combine into final formula\n",
    "formula = 'los_capped ~ ' + ' + '.join(formula_parts)\n",
    "print(f\"Model formula: {formula}\")\n",
    "\n",
    "# Add formula to document\n",
    "doc.add_paragraph(f\"Model formula: {formula}\")\n",
    "\n",
    "# Drop rows with missing values in formula variables\n",
    "##formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "formula_vars = ['los_capped'] + continuous_vars + categorical_model_vars\n",
    "df_clean_nb = df_clean[formula_vars].dropna()\n",
    "df_clean_nb = df_clean_nb.reset_index(drop=True)\n",
    "print(f\"Number of rows in df_clean_nb after dropping missing values: {len(df_clean_nb)}\")\n",
    "\n",
    "# Fit negative binomial model\n",
    "nb_model = smf.glm(formula=formula, \n",
    "                  data=df_clean_nb, \n",
    "                  family=sm.families.NegativeBinomial(link=sm.families.links.log()))\n",
    "\n",
    "try:\n",
    "    nb_results = nb_model.fit()\n",
    "    print(\"\\nNegative Binomial Regression Results:\")\n",
    "    summary_text = str(nb_results.summary())\n",
    "    print(summary_text)\n",
    "    \n",
    "    # Add model summary to document\n",
    "    doc.add_paragraph('\\nModel Summary:')\n",
    "    for line in summary_text.split('\\n'):\n",
    "        doc.add_paragraph(line)\n",
    "    \n",
    "    # Convert coefficients to incident rate ratios (IRR)\n",
    "    print(\"\\nIncident Rate Ratios (IRR):\")\n",
    "    irr = np.exp(nb_results.params)\n",
    "    irr_conf = np.exp(nb_results.conf_int())\n",
    "    irr_df = pd.DataFrame({'IRR': irr, 'Lower CI': irr_conf[0], 'Upper CI': irr_conf[1], \n",
    "                          'P-value': nb_results.pvalues})\n",
    "    print(irr_df)\n",
    "    \n",
    "    # Add IRR table to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Incident Rate Ratios (IRR)', level=2)\n",
    "    irr_table = doc.add_table(rows=len(irr_df)+1, cols=5)\n",
    "    irr_table.style = 'Table Grid'\n",
    "    irr_table.cell(0, 0).text = 'Variable'\n",
    "    irr_table.cell(0, 1).text = 'IRR'\n",
    "    irr_table.cell(0, 2).text = 'Lower CI'\n",
    "    irr_table.cell(0, 3).text = 'Upper CI'\n",
    "    irr_table.cell(0, 4).text = 'P-value'\n",
    "    \n",
    "    for i, (var, row) in enumerate(irr_df.iterrows(), 1):\n",
    "        irr_table.cell(i, 0).text = str(var)\n",
    "        irr_table.cell(i, 1).text = f\"{row['IRR']:.4f}\"\n",
    "        irr_table.cell(i, 2).text = f\"{row['Lower CI']:.4f}\"\n",
    "        irr_table.cell(i, 3).text = f\"{row['Upper CI']:.4f}\"\n",
    "        irr_table.cell(i, 4).text = f\"{row['P-value']:.4f}\"\n",
    "    \n",
    "    # Predictions and diagnostics\n",
    "    df_clean_nb['predicted'] = nb_results.predict()\n",
    "    df_clean_nb['residuals'] = df_clean_nb['los_capped'] - df_clean_nb['predicted']\n",
    "    \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_clean_nb['predicted'], df_clean_nb['residuals'], alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='-')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residual Plot')\n",
    "    plt.tight_layout()\n",
    "    residuals_img = BytesIO()\n",
    "    plt.savefig(residuals_img, format='png')\n",
    "    residuals_img.seek(0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Add residuals plot to document\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Diagnostics', level=2)\n",
    "    doc.add_picture(residuals_img, width=Inches(6))\n",
    "    doc.add_paragraph('Figure 3: Residuals Plot')\n",
    "    \n",
    "    # Check for heterogeneity across states if us_state is in the data\n",
    "    if 'us_state_enc' in df_clean.columns or 'us_state' in df_clean.columns:\n",
    "        state_var = 'us_state_enc' if 'us_state_enc' in df_clean.columns else 'us_state'\n",
    "        state_means = df_clean.groupby(state_var)['los_capped'].mean().sort_values()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        state_means.plot(kind='bar')\n",
    "        plt.xlabel('State')\n",
    "        plt.ylabel('Average Length of Stay')\n",
    "        plt.title('Mean Length of Stay by State')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        los_by_state_img = BytesIO()\n",
    "        plt.savefig(los_by_state_img, format='png')\n",
    "        los_by_state_img.seek(0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Add state analysis to document\n",
    "        doc.add_paragraph('\\n')\n",
    "        doc.add_heading('State Analysis', level=2)\n",
    "        doc.add_picture(los_by_state_img, width=Inches(6))\n",
    "        doc.add_paragraph('Figure 4: Mean Length of Stay by State')\n",
    "    \n",
    "    # Approximated Multilevel Model\n",
    "    doc.add_paragraph('\\n')\n",
    "    doc.add_heading('Approximated Multilevel Model', level=1)\n",
    "    doc.add_paragraph('Using MixedLM to approximate a multilevel model with random effects for states.')\n",
    "    \n",
    "    # Debugging: Check df_clean_nb and the condition\n",
    "    print(\"Columns in df_clean_nb:\", df_clean_nb.columns.tolist())\n",
    "    print(\"Checking if 'us_state_enc' is in df_clean_nb.columns:\", 'us_state_enc' in df_clean_nb.columns)\n",
    "\n",
    "    # Check if us_state variable exists for multilevel modeling\n",
    "    if 'us_state_enc' in df_clean_nb.columns:\n",
    "        # For demonstration, we'll use a linear mixed model as an approximation\n",
    "        # Prepare model variables\n",
    "        \n",
    "        # Ensure no missing values in variables used for mixed effects model\n",
    "        model_vars = ['los_capped'] + continuous_vars + categorical_model_vars + ['us_state_enc']\n",
    "        df_clean_model = df_clean_nb[model_vars].dropna()\n",
    "\n",
    "        df_clean_model = df_clean_model.reset_index(drop=True)\n",
    "        \n",
    "        y = df_clean_model['los_capped']\n",
    "        \n",
    "        # Create X matrix for fixed effects\n",
    "        X_vars = []\n",
    "        for var in continuous_vars:\n",
    "            if var in df_clean_model.columns:\n",
    "                X_vars.append(var)\n",
    "        \n",
    "        X = df_clean_model[X_vars].copy()\n",
    "        \n",
    "        # Add categorical variables (one-hot encoded)\n",
    "        for var in categorical_model_vars:\n",
    "            if var in df_clean_model.columns and var != 'us_state_enc':  # Exclude the grouping variable\n",
    "                dummies = pd.get_dummies(df_clean_model[var], prefix=var, drop_first=True)\n",
    "                X = pd.concat([X, dummies], axis=1)\n",
    "        \n",
    "        # Add intercept\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        # Define groups for random effects\n",
    "        groups = df_clean_model['us_state_enc']\n",
    "\n",
    "        print(f\"Length of df_clean_model: {len(df_clean_model)}\")\n",
    "        print(f\"Length of y: {len(y)}\")\n",
    "        print(f\"Number of rows in X: {X.shape[0]}\")\n",
    "        print(f\"Length of groups: {len(groups)}\")\n",
    "\n",
    "        if len(y) != X.shape[0] or len(y) != len(groups):\n",
    "            print('Length mismatch between y, X, and groups. Check data preparation.')\n",
    "            print(f\"y length:{len(y)}\")\n",
    "            print(f\"X rows: {X.shape[0]}\")\n",
    "            print(f\"groups length: {len(groups)}\")\n",
    "            # Check for NaN values in X\n",
    "            print(\"NaN counts in X columns:\")\n",
    "            print(X.isnull().sum())\n",
    "            raise ValueError(\"Lengths of y, X, and groups do not match!\")\n",
    "\n",
    "\n",
    "        \n",
    "        # Fit mixed effects model\n",
    "        mixed_model = MixedLM(y, X, groups)\n",
    "        try:\n",
    "            mixed_results = mixed_model.fit()\n",
    "            mixed_summary = str(mixed_results.summary())\n",
    "            print(\"\\nApproximated Multilevel Model Results:\")\n",
    "            print(mixed_summary)\n",
    "            \n",
    "            # Add to document\n",
    "            doc.add_paragraph('Model Summary:')\n",
    "            for line in mixed_summary.split('\\n'):\n",
    "                doc.add_paragraph(line)\n",
    "            \n",
    "            # Add variance components\n",
    "            doc.add_paragraph('\\nVariance Components:')\n",
    "            vc_table = doc.add_table(rows=3, cols=2)\n",
    "            vc_table.style = 'Table Grid'\n",
    "            vc_table.cell(0, 0).text = 'Component'\n",
    "            vc_table.cell(0, 1).text = 'Estimate'\n",
    "            vc_table.cell(1, 0).text = 'State Random Effect Variance'\n",
    "            vc_table.cell(1, 1).text = f\"{mixed_results.cov_re.iloc[0, 0]:.4f}\"\n",
    "            vc_table.cell(2, 0).text = 'Residual Variance'\n",
    "            vc_table.cell(2, 1).text = f\"{mixed_results.scale:.4f}\"\n",
    "            \n",
    "            # Calculate intraclass correlation coefficient (ICC)\n",
    "            state_var = mixed_results.cov_re.iloc[0, 0]\n",
    "            residual_var = mixed_results.scale\n",
    "            icc = state_var / (state_var + residual_var)\n",
    "            \n",
    "            doc.add_paragraph(f'\\nIntraclass Correlation Coefficient (ICC): {icc:.4f}')\n",
    "            doc.add_paragraph('The ICC represents the proportion of the total variance in length of stay ' +\n",
    "                             'that is attributable to differences between states.')\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error fitting mixed model: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            doc.add_paragraph(error_msg)\n",
    "            doc.add_paragraph(\"The mixed effects model failed to converge. This can happen due to \" +\n",
    "                             \"insufficient variation in the grouping variable or other model specification issues.\")\n",
    "    else:\n",
    "        no_state_msg = \"State variable not found for multilevel modeling.\"\n",
    "        print(no_state_msg)\n",
    "        doc.add_paragraph(no_state_msg)\n",
    "    \n",
    "except Exception as e:\n",
    "    error_msg = f\"\\nError in model fitting: {str(e)}\"\n",
    "    print(error_msg)\n",
    "    doc.add_paragraph(error_msg)\n",
    "    doc.add_paragraph(\"You may need to check your data or consider using a different modeling approach.\")\n",
    "\n",
    "# Save the Word document\n",
    "print(\"\\nPlease select where to save the Word document...\")\n",
    "doc_path = select_file(\n",
    "    \"Save Analysis Report As\", \n",
    "    [(\"Word Document\", \"*.docx\"), (\"All files\", \"*.*\")],\n",
    "    save=True\n",
    ")\n",
    "\n",
    "if doc_path:\n",
    "    if not doc_path.endswith('.docx'):\n",
    "        doc_path += '.docx'\n",
    "    doc.save(doc_path)\n",
    "    print(f\"Analysis report saved to: {doc_path}\")\n",
    "else:\n",
    "    print(\"Document not saved as no location was selected.\")\n",
    "\n",
    "print(\"\\nAnalysis complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(continuous_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136252\n"
     ]
    }
   ],
   "source": [
    "print(len(df_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(purpose_enc_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los_capped                float64\n",
      "immigrant_population      float64\n",
      "import_from_slu           float64\n",
      "age                       float64\n",
      "distance_miles            float64\n",
      "state_percapita_income    float64\n",
      "state_unemployment        float64\n",
      "sex_enc                      int8\n",
      "marital_status_enc           int8\n",
      "employment_status_enc        int8\n",
      "purpose_simple            float64\n",
      "accomd_type_enc              int8\n",
      "month_travel                int64\n",
      "us_state_enc                 int8\n",
      "predicted                 float64\n",
      "residuals                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_clean_nb.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtypes:\n",
      "const                      float64\n",
      "immigrant_population       float64\n",
      "import_from_slu            float64\n",
      "age                        float64\n",
      "distance_miles             float64\n",
      "state_percapita_income     float64\n",
      "state_unemployment         float64\n",
      "sex_enc_0                     bool\n",
      "sex_enc_1                     bool\n",
      "marital_status_enc_0          bool\n",
      "marital_status_enc_1          bool\n",
      "marital_status_enc_2          bool\n",
      "employment_status_enc_0       bool\n",
      "employment_status_enc_1       bool\n",
      "employment_status_enc_2       bool\n",
      "purpose_simple_2.0            bool\n",
      "purpose_simple_3.0            bool\n",
      "purpose_simple_4.0            bool\n",
      "purpose_simple_5.0            bool\n",
      "accomd_type_enc_1             bool\n",
      "accomd_type_enc_2             bool\n",
      "month_travel_2                bool\n",
      "month_travel_3                bool\n",
      "month_travel_4                bool\n",
      "month_travel_5                bool\n",
      "month_travel_6                bool\n",
      "month_travel_7                bool\n",
      "month_travel_8                bool\n",
      "month_travel_9                bool\n",
      "month_travel_10               bool\n",
      "month_travel_11               bool\n",
      "month_travel_12               bool\n",
      "dtype: object\n",
      "X shape: (132666, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"X dtypes:\")\n",
    "print(X.dtypes)\n",
    "print(\"X shape:\", X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y dtypes:\n",
      "float64\n",
      "y shape: (132666,)\n"
     ]
    }
   ],
   "source": [
    "print(\"y dtypes:\")\n",
    "print(y.dtypes)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statsmodels version: 0.14.4\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import statsmodels\n",
    "import pandas\n",
    "print(\"statsmodels version:\", statsmodels.__version__)\n",
    "print(\"pandas version:\", pandas.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jlslu2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
